{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tavi1402/Data_Science_bootcamp/blob/main/5_5_python_gradient_boosting_machines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fixed-plastic",
      "metadata": {
        "id": "fixed-plastic"
      },
      "source": [
        "# Gradient Boosting Machines (GBMs) with XGBoost\n",
        "\n",
        "This tutorial is a part of [Machine Learning with Python: Zero to GBMs](https://zerotogbms.com) and [Zero to Data Science Bootcamp by Jovian](https://zerotodatascience.com)\n",
        "\n",
        "![](https://i.imgur.com/6MYc56a.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rural-shelf",
      "metadata": {
        "id": "rural-shelf"
      },
      "source": [
        "The following topics are covered in this tutorial:\n",
        "\n",
        "- Downloading a real-world dataset from a Kaggle competition\n",
        "- Performing feature engineering and prepare the dataset for training\n",
        "- Training and interpreting a gradient boosting model using XGBoost\n",
        "- Training with KFold cross validation and ensembling results\n",
        "- Configuring the gradient boosting model and tuning hyperparamters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "honey-batch",
      "metadata": {
        "id": "honey-batch"
      },
      "source": [
        "Let's begin by installing the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "discrete-victoria",
      "metadata": {
        "id": "discrete-victoria"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "structured-sleep",
      "metadata": {
        "id": "structured-sleep"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "binary-album",
      "metadata": {
        "id": "binary-album"
      },
      "source": [
        "## Problem Statement\n",
        "\n",
        "This tutorial takes a practical and coding-focused approach. We'll learn gradient boosting by applying it to a real-world dataset from the [Rossmann Store Sales](https://www.kaggle.com/c/rossmann-store-sales) competition on Kaggle:\n",
        "\n",
        "> Rossmann operates over 3,000 drug stores in 7 European countries. Currently, Rossmann store managers are tasked with predicting their daily sales for up to six weeks in advance. Store sales are influenced by many factors, including promotions, competition, school and state holidays, seasonality, and locality.\n",
        ">\n",
        ">\n",
        "> With thousands of individual managers predicting sales based on their unique circumstances, the accuracy of results can be quite varied. You are provided with historical sales data for 1,115 Rossmann stores. The task is to forecast the \"Sales\" column for the test set. Note that some stores in the dataset were temporarily closed for refurbishment.\n",
        ">\n",
        "> View and download the data here: https://www.kaggle.com/c/rossmann-store-sales/data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "alpha-polymer",
      "metadata": {
        "id": "alpha-polymer"
      },
      "source": [
        "## Downloading the Data\n",
        "\n",
        "We can download the dataset from Kaggle directly within the Jupyter notebook using the `opendatasets` library. Make sure to [accept the competition rules](https://www.kaggle.com/c/rossmann-store-sales/rules) before executing the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stainless-honor",
      "metadata": {
        "id": "stainless-honor"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cooperative-match",
      "metadata": {
        "id": "cooperative-match"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "composite-shade",
      "metadata": {
        "id": "composite-shade"
      },
      "source": [
        "You'll be asked to provide your Kaggle credentials to download the data. Follow these instructions: http://bit.ly/kaggle-creds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beginning-appeal",
      "metadata": {
        "id": "beginning-appeal"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "eastern-paintball",
      "metadata": {
        "id": "eastern-paintball"
      },
      "source": [
        "Let's load the data into Pandas dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fewer-laptop",
      "metadata": {
        "id": "fewer-laptop"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sophisticated-belle",
      "metadata": {
        "id": "sophisticated-belle"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "favorite-recovery",
      "metadata": {
        "id": "favorite-recovery"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lovely-shelter",
      "metadata": {
        "id": "lovely-shelter"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sustainable-french",
      "metadata": {
        "id": "sustainable-french"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "interracial-conditions",
      "metadata": {
        "id": "interracial-conditions"
      },
      "source": [
        "> **EXERCISE**: Read the data description provided on the competition page to understand what the values in each column of `store_df` represent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "every-mambo",
      "metadata": {
        "id": "every-mambo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "obvious-immune",
      "metadata": {
        "id": "obvious-immune"
      },
      "source": [
        "Let's merge the information from `store_df` into `train_df` and `test_df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "weird-tracker",
      "metadata": {
        "id": "weird-tracker"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "solved-actor",
      "metadata": {
        "id": "solved-actor"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "pursuant-incident",
      "metadata": {
        "id": "pursuant-incident"
      },
      "source": [
        "> **EXERCISE**: Perform exploratory data analysis and visualization on the dataset. Study the distribution of values in each column, and their relationship with the target column `Sales`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "chubby-variable",
      "metadata": {
        "id": "chubby-variable"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "twelve-pastor",
      "metadata": {
        "id": "twelve-pastor"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "confidential-identity",
      "metadata": {
        "id": "confidential-identity"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sustained-characteristic",
      "metadata": {
        "id": "sustained-characteristic"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "juvenile-lying",
      "metadata": {
        "id": "juvenile-lying"
      },
      "source": [
        "## Preprocessing and Feature Engineering\n",
        "\n",
        "Let's take a look at the available columns, and figure out if we can create new columns or apply any useful transformations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "short-floor",
      "metadata": {
        "id": "short-floor"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "anonymous-vermont",
      "metadata": {
        "id": "anonymous-vermont"
      },
      "source": [
        "\n",
        "### Date\n",
        "\n",
        "First, let's convert `Date` to a `datetime` column and extract different parts of the date."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "driving-ecuador",
      "metadata": {
        "id": "driving-ecuador"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "banned-daughter",
      "metadata": {
        "id": "banned-daughter"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "smooth-vegetarian",
      "metadata": {
        "id": "smooth-vegetarian"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "accredited-behavior",
      "metadata": {
        "id": "accredited-behavior"
      },
      "source": [
        "### Store Open/Closed\n",
        "\n",
        "Next, notice that the sales are zero whenever the store is closed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "middle-handy",
      "metadata": {
        "id": "middle-handy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "partial-mount",
      "metadata": {
        "id": "partial-mount"
      },
      "source": [
        "Instead of trying to model this relationship, it would be better to hard-code it in our predictions, and remove the rows where the store is closed. We won't remove any rows from the test set, since we need to make predictions for every row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wooden-fifteen",
      "metadata": {
        "id": "wooden-fifteen"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cardiovascular-giving",
      "metadata": {
        "id": "cardiovascular-giving"
      },
      "source": [
        "### Competition\n",
        "\n",
        "Next, we can use the columns `CompetitionOpenSince[Month/Year]` columns from `store_df` to compute the number of months for which a competitor has been open near the store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "interim-avatar",
      "metadata": {
        "id": "interim-avatar"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "separate-confirmation",
      "metadata": {
        "id": "separate-confirmation"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "numerical-concept",
      "metadata": {
        "id": "numerical-concept"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "supposed-nutrition",
      "metadata": {
        "id": "supposed-nutrition"
      },
      "source": [
        "Let's view the results of the new columns we've created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "single-wesley",
      "metadata": {
        "id": "single-wesley"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "egyptian-fireplace",
      "metadata": {
        "id": "egyptian-fireplace"
      },
      "source": [
        "### Additional Promotion\n",
        "\n",
        "We can also add some additional columns to indicate how long a store has been running `Promo2` and whether a new round of `Promo2` starts in the current month."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "occasional-employee",
      "metadata": {
        "id": "occasional-employee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "orange-beijing",
      "metadata": {
        "id": "orange-beijing"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "forced-surfing",
      "metadata": {
        "id": "forced-surfing"
      },
      "source": [
        "Let's view the results of the columns we've created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "looking-october",
      "metadata": {
        "id": "looking-october"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "serial-politics",
      "metadata": {
        "id": "serial-politics"
      },
      "source": [
        "The features related to competition and promotion are now much more useful."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "furnished-property",
      "metadata": {
        "id": "furnished-property"
      },
      "source": [
        "### Input and Target Columns\n",
        "\n",
        "Let's select the columns that we'll use for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "continent-mountain",
      "metadata": {
        "id": "continent-mountain"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "miniature-ottawa",
      "metadata": {
        "id": "miniature-ottawa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "available-observation",
      "metadata": {
        "id": "available-observation"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unlike-consciousness",
      "metadata": {
        "id": "unlike-consciousness"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "middle-spank",
      "metadata": {
        "id": "middle-spank"
      },
      "source": [
        "Let's also identify numeric and categorical columns. Note that we can treat binary categorical columns (0/1) as numeric columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "equipped-wrapping",
      "metadata": {
        "id": "equipped-wrapping"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "expired-wrapping",
      "metadata": {
        "id": "expired-wrapping"
      },
      "source": [
        "### Impute missing numerical data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stupid-disorder",
      "metadata": {
        "id": "stupid-disorder"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stainless-adobe",
      "metadata": {
        "id": "stainless-adobe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "abroad-commitment",
      "metadata": {
        "id": "abroad-commitment"
      },
      "source": [
        "Seems like competition distance is the only missing value, and we can simply fill it with the highest value (to indicate that competition is very far away)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "suspended-illinois",
      "metadata": {
        "id": "suspended-illinois"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ranging-domestic",
      "metadata": {
        "id": "ranging-domestic"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "widespread-percentage",
      "metadata": {
        "id": "widespread-percentage"
      },
      "source": [
        "### Scale Numeric Values\n",
        "\n",
        "Let's scale numeric values to the 0 to 1 range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "verified-weight",
      "metadata": {
        "id": "verified-weight"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "small-sunset",
      "metadata": {
        "id": "small-sunset"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "neither-madagascar",
      "metadata": {
        "id": "neither-madagascar"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cutting-thompson",
      "metadata": {
        "id": "cutting-thompson"
      },
      "source": [
        "### Encode Categorical Columns\n",
        "\n",
        "<img src=\"https://i.imgur.com/n8GuiOO.png\" width=\"640\">\n",
        "\n",
        "Let's one-hot encode categorical columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "corrected-jacket",
      "metadata": {
        "id": "corrected-jacket"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "manual-hands",
      "metadata": {
        "id": "manual-hands"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "transparent-participation",
      "metadata": {
        "id": "transparent-participation"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "maritime-mailman",
      "metadata": {
        "id": "maritime-mailman"
      },
      "source": [
        "Finally, let's extract out all the numeric data for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "floating-plant",
      "metadata": {
        "id": "floating-plant"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "covered-conversation",
      "metadata": {
        "id": "covered-conversation"
      },
      "source": [
        "We haven't created a validation set yet, because we'll use K-fold cross validation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unlikely-apparel",
      "metadata": {
        "id": "unlikely-apparel"
      },
      "source": [
        "> **EXERCISE**: Look through the notebooks created by participants in the Kaggle competition and apply some other ideas for feature engineering. https://www.kaggle.com/c/rossmann-store-sales/code?competitionId=4594&sortBy=voteCount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "novel-image",
      "metadata": {
        "id": "novel-image"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "closed-fellow",
      "metadata": {
        "id": "closed-fellow"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "chicken-energy",
      "metadata": {
        "id": "chicken-energy"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "surprising-reggae",
      "metadata": {
        "id": "surprising-reggae"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "minor-casting",
      "metadata": {
        "id": "minor-casting"
      },
      "source": [
        "## Gradient Boosting\n",
        "\n",
        "We're now ready to train our gradient boosting machine (GBM) model. Here's how a GBM model works:\n",
        "\n",
        "1. The average value of the target column and uses as an initial prediction every input.\n",
        "2. The residuals (difference) of the predictions with the targets are computed.\n",
        "3. A decision tree of limited depth is trained to **predict just the residuals** for each input.\n",
        "4. Predictions from the decision tree are scaled using a parameter called the learning rate (this prevents overfitting)\n",
        "5. Scaled predictions for the tree are added to the previous predictions to obtain the new and improved predictions.\n",
        "6. Steps 2 to 5 are repeated to create new decision trees, each of which is trained to predict just the residuals from the previous prediction.\n",
        "\n",
        "The term \"gradient\" refers to the fact that each decision tree is trained with the purpose of reducing the loss from the previous iteration (similar to gradient descent). The term \"boosting\" refers the general technique of training new models to improve the results of an existing model.\n",
        "\n",
        "> **EXERCISE**: Can you describe in your own words how a gradient boosting machine is different from a random forest?\n",
        "\n",
        "\n",
        "For a mathematical explanation of gradient boosting, check out the following resources:\n",
        "\n",
        "- [XGBoost Documentation](https://xgboost.readthedocs.io/en/latest/tutorials/model.html)\n",
        "- [Video Tutorials on StatQuest](https://www.youtube.com/watch?v=3CC4N4z3GJc&list=PLblh5JKOoLUJjeXUvUE0maghNuY2_5fY6)\n",
        "\n",
        "Here's a visual representation of gradient boosting:\n",
        "\n",
        "![](https://miro.medium.com/max/560/1*85QHtH-49U7ozPpmA5cAaw.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "heard-mentor",
      "metadata": {
        "id": "heard-mentor"
      },
      "source": [
        "### Training\n",
        "\n",
        "To train a GBM, we can use the `XGBRegressor` class from the [`XGBoost`](https://xgboost.readthedocs.io/en/latest/) library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "complicated-southeast",
      "metadata": {
        "id": "complicated-southeast"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "serious-values",
      "metadata": {
        "id": "serious-values"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "legendary-diving",
      "metadata": {
        "id": "legendary-diving"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "helpful-toyota",
      "metadata": {
        "id": "helpful-toyota"
      },
      "source": [
        "Let's train the model using `model.fit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "associate-customer",
      "metadata": {
        "id": "associate-customer"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "solved-billion",
      "metadata": {
        "id": "solved-billion"
      },
      "source": [
        "> **EXERCISE**: Explain how the `.fit` method of `XGBRegressor` applies the iterative machine learning workflow to train the model using the training data.\n",
        ">\n",
        "> <img src=\"https://www.deepnetts.com/blog/wp-content/uploads/2019/02/SupervisedLearning.png\" width=\"480\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fitting-mount",
      "metadata": {
        "id": "fitting-mount"
      },
      "source": [
        "### Prediction\n",
        "\n",
        "We can now make predictions and evaluate the model using `model.predict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "informational-sheffield",
      "metadata": {
        "id": "informational-sheffield"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "minute-perry",
      "metadata": {
        "id": "minute-perry"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "stupid-pixel",
      "metadata": {
        "id": "stupid-pixel"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "Let's evaluate the predictions using RMSE error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "together-christmas",
      "metadata": {
        "id": "together-christmas"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prescription-premiere",
      "metadata": {
        "id": "prescription-premiere"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "accompanied-swimming",
      "metadata": {
        "id": "accompanied-swimming"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "split-forty",
      "metadata": {
        "id": "split-forty"
      },
      "source": [
        "### Visualization\n",
        "\n",
        "We can visualize individual trees using `plot_tree` (note: this requires the `graphviz` library to be installed)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "threatened-panel",
      "metadata": {
        "id": "threatened-panel"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "italic-medication",
      "metadata": {
        "id": "italic-medication"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "square-repeat",
      "metadata": {
        "id": "square-repeat"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "available-mills",
      "metadata": {
        "id": "available-mills"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "quiet-arthur",
      "metadata": {
        "id": "quiet-arthur"
      },
      "source": [
        "Notice how the trees only compute residuals, and not the actual target value. We can also visualize the tree as text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "renewable-things",
      "metadata": {
        "id": "renewable-things"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dedicated-attribute",
      "metadata": {
        "id": "dedicated-attribute"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reported-official",
      "metadata": {
        "id": "reported-official"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "acceptable-stupid",
      "metadata": {
        "id": "acceptable-stupid"
      },
      "source": [
        "### Feature importance\n",
        "\n",
        "Just like decision trees and random forests, XGBoost also provides a feature importance score for each column in the input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "circular-study",
      "metadata": {
        "id": "circular-study"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "related-college",
      "metadata": {
        "id": "related-college"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "academic-element",
      "metadata": {
        "scrolled": true,
        "id": "academic-element"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "optical-diameter",
      "metadata": {
        "id": "optical-diameter"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "decent-beginning",
      "metadata": {
        "id": "decent-beginning"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "union-intro",
      "metadata": {
        "id": "union-intro"
      },
      "source": [
        "## K Fold Cross Validation\n",
        "\n",
        "Notice that we didn't create a validation set before training our XGBoost model. We'll use a different validation strategy this time, called K-fold cross validation ([source](https://vitalflux.com/k-fold-cross-validation-python-example/)):\n",
        "\n",
        "![](https://vitalflux.com/wp-content/uploads/2020/08/Screenshot-2020-08-15-at-11.13.53-AM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "allied-amsterdam",
      "metadata": {
        "id": "allied-amsterdam"
      },
      "source": [
        "Scikit-learn provides utilities for performing K fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "congressional-killer",
      "metadata": {
        "id": "congressional-killer"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "confused-bulletin",
      "metadata": {
        "id": "confused-bulletin"
      },
      "source": [
        "Let's define a helper function `train_and_evaluate` which trains a model the given parameters and returns the trained model, training error and validation error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "novel-gazette",
      "metadata": {
        "id": "novel-gazette"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "disciplinary-japanese",
      "metadata": {
        "id": "disciplinary-japanese"
      },
      "source": [
        "Now, we can use the `KFold` utility to create the different training/validations splits and train a separate model for each fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "registered-surveillance",
      "metadata": {
        "id": "registered-surveillance"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bulgarian-press",
      "metadata": {
        "id": "bulgarian-press"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "swiss-connecticut",
      "metadata": {
        "id": "swiss-connecticut"
      },
      "source": [
        "Let's also define a function to average predictions from the 5 different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "specified-pierre",
      "metadata": {
        "id": "specified-pierre"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "coordinated-hindu",
      "metadata": {
        "id": "coordinated-hindu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "moved-indie",
      "metadata": {
        "id": "moved-indie"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "metric-meter",
      "metadata": {
        "id": "metric-meter"
      },
      "source": [
        "We can now use `predict_avg` to make predictions for the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "royal-population",
      "metadata": {
        "id": "royal-population"
      },
      "source": [
        "## Hyperparameter Tuning and Regularization\n",
        "\n",
        "Just like other machine learning models, there are several hyperparameters we can to adjust the capacity of model and reduce overfitting.\n",
        "\n",
        "<img src=\"https://i.imgur.com/EJCrSZw.png\" width=\"480\">\n",
        "\n",
        "Check out the following resources to learn more about hyperparameter supported by XGBoost:\n",
        "\n",
        "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor\n",
        "- https://xgboost.readthedocs.io/en/latest/parameter.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "funky-canon",
      "metadata": {
        "id": "funky-canon"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dominant-appeal",
      "metadata": {
        "id": "dominant-appeal"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "handy-grave",
      "metadata": {
        "id": "handy-grave"
      },
      "source": [
        "Here's a helper function to test hyperparameters with K-fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "successful-devices",
      "metadata": {
        "id": "successful-devices"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "invisible-america",
      "metadata": {
        "id": "invisible-america"
      },
      "source": [
        "Since it may take a long time to perform 5-fold cross validation for each set of parameters we wish to try, we'll just pick a random 10% sample of the dataset as the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "indoor-mason",
      "metadata": {
        "id": "indoor-mason"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "progressive-primary",
      "metadata": {
        "id": "progressive-primary"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cordless-filling",
      "metadata": {
        "id": "cordless-filling"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "sorted-century",
      "metadata": {
        "id": "sorted-century"
      },
      "source": [
        "#### `n_estimators`\n",
        "\n",
        "The number of trees to be created. More trees = greater capacity of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "decimal-briefs",
      "metadata": {
        "id": "decimal-briefs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adjacent-blade",
      "metadata": {
        "id": "adjacent-blade"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "capable-ordinary",
      "metadata": {
        "id": "capable-ordinary"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "affiliated-separation",
      "metadata": {
        "id": "affiliated-separation"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "strange-shelf",
      "metadata": {
        "id": "strange-shelf"
      },
      "source": [
        "> **EXERCISE**: Experiment with different values of `n_estimators`, plot a graph of the training and validation error and determine the best value for `n_estimators`.\n",
        ">\n",
        "> <img src=\"https://i.imgur.com/EJCrSZw.png\" width=\"360\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "silent-electron",
      "metadata": {
        "id": "silent-electron"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "provincial-kruger",
      "metadata": {
        "id": "provincial-kruger"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "talented-tunisia",
      "metadata": {
        "id": "talented-tunisia"
      },
      "source": [
        "#### `max_depth`\n",
        "\n",
        "As you increase the max depth of each tree, the capacity of the tree increases and it can capture more information about the training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "opened-serve",
      "metadata": {
        "id": "opened-serve"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "brave-subdivision",
      "metadata": {
        "id": "brave-subdivision"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "atomic-spouse",
      "metadata": {
        "id": "atomic-spouse"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "handy-tongue",
      "metadata": {
        "id": "handy-tongue"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "instrumental-rental",
      "metadata": {
        "id": "instrumental-rental"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "colonial-mentor",
      "metadata": {
        "id": "colonial-mentor"
      },
      "source": [
        "> **EXERCISE**: Experiment with different values of `max_depth`, plot a graph of the training and validation error and determine the optimal.\n",
        ">\n",
        "> <img src=\"https://i.imgur.com/EJCrSZw.png\" width=\"360\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "early-integrity",
      "metadata": {
        "id": "early-integrity"
      },
      "source": [
        "#### `learning_rate`\n",
        "\n",
        "The scaling factor to be applied to the prediction of each tree. A very high learning rate (close to 1) will lead to overfitting, and a low learning rate (close to 0) will lead to underfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "russian-irrigation",
      "metadata": {
        "id": "russian-irrigation"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "several-niger",
      "metadata": {
        "id": "several-niger"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "precious-boxing",
      "metadata": {
        "id": "precious-boxing"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "threatened-filename",
      "metadata": {
        "id": "threatened-filename"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stunning-sheriff",
      "metadata": {
        "id": "stunning-sheriff"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "collected-louis",
      "metadata": {
        "id": "collected-louis"
      },
      "source": [
        "> **EXERCISE**: Experiment with different values of `learning_rate`, plot a graph of the training and validation error and determine the optimal.\n",
        ">\n",
        "> <img src=\"https://i.imgur.com/EJCrSZw.png\" width=\"360\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "colonial-enemy",
      "metadata": {
        "id": "colonial-enemy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "clear-procedure",
      "metadata": {
        "id": "clear-procedure"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "superior-paintball",
      "metadata": {
        "id": "superior-paintball"
      },
      "source": [
        "#### `booster`\n",
        "\n",
        "Instead of using Decision Trees, XGBoost can also train a linear model for each iteration. This can be configured using `booster`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ranking-steel",
      "metadata": {
        "id": "ranking-steel"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "conventional-distance",
      "metadata": {
        "id": "conventional-distance"
      },
      "source": [
        "Clearly, a linear model is not well suited for this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "asian-philippines",
      "metadata": {
        "id": "asian-philippines"
      },
      "source": [
        "> **EXERCISE**: Exeperiment with other hyperparameters like `gamma`, `min_child_weight`, `max_delta_step`, `subsample`, `colsample_bytree` etc. and find their optimal values. Learn more about them here: https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "original-currency",
      "metadata": {
        "id": "original-currency"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reflected-young",
      "metadata": {
        "id": "reflected-young"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "steady-sociology",
      "metadata": {
        "id": "steady-sociology"
      },
      "source": [
        "> **EXERCISE**: Train a model with your best hyperparmeters and evaluate its peformance using 5-fold cross validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "opposed-saskatchewan",
      "metadata": {
        "id": "opposed-saskatchewan"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beautiful-associate",
      "metadata": {
        "id": "beautiful-associate"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "copyrighted-consistency",
      "metadata": {
        "id": "copyrighted-consistency"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "phantom-lloyd",
      "metadata": {
        "id": "phantom-lloyd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "committed-radar",
      "metadata": {
        "id": "committed-radar"
      },
      "source": [
        "## Putting it Together and Making Predictions\n",
        "\n",
        "Let's train a final model on the entire training set with custom hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "private-snowboard",
      "metadata": {
        "id": "private-snowboard"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sudden-geneva",
      "metadata": {
        "id": "sudden-geneva"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "challenging-religious",
      "metadata": {
        "id": "challenging-religious"
      },
      "source": [
        "Now that the model is trained, we can make predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vietnamese-lucas",
      "metadata": {
        "id": "vietnamese-lucas"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "permanent-garbage",
      "metadata": {
        "id": "permanent-garbage"
      },
      "source": [
        "Let's add the predictions into `submission_df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "empty-weapon",
      "metadata": {
        "id": "empty-weapon"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "geological-football",
      "metadata": {
        "id": "geological-football"
      },
      "source": [
        "Recall, however, if if the store is not open, then the sales must be 0. Thus, wherever the value of `Open` in the test set is 0, we can set the sales to 0. Also, there some missing values for `Open` in the test set. We'll replace them with 1 (open)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nuclear-prophet",
      "metadata": {
        "id": "nuclear-prophet"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "novel-coverage",
      "metadata": {
        "id": "novel-coverage"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "expanded-copper",
      "metadata": {
        "id": "expanded-copper"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "agreed-characteristic",
      "metadata": {
        "id": "agreed-characteristic"
      },
      "source": [
        "We can now save the predictions as a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bottom-intranet",
      "metadata": {
        "id": "bottom-intranet"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ranging-cologne",
      "metadata": {
        "id": "ranging-cologne"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "insured-durham",
      "metadata": {
        "id": "insured-durham"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cosmetic-right",
      "metadata": {
        "id": "cosmetic-right"
      },
      "source": [
        "We can now make a submission on this page and check our score: https://www.kaggle.com/c/rossmann-store-sales/submit\n",
        "\n",
        "![](https://i.imgur.com/bQ0lpSJ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "explicit-affiliation",
      "metadata": {
        "id": "explicit-affiliation"
      },
      "source": [
        "> **EXERCISE**: Experiment with different models and hyperparameters and try to beat the above score. Take inspiration from the [top notebooks](https://www.kaggle.com/c/rossmann-store-sales/code?competitionId=4594&sortBy=voteCount) on the \"Code\" tab of the competition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "known-terminology",
      "metadata": {
        "id": "known-terminology"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "valuable-detail",
      "metadata": {
        "id": "valuable-detail"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "affected-frost",
      "metadata": {
        "id": "affected-frost"
      },
      "source": [
        "> **EXERCISE**: Save the model and all the other required objects using `joblib`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adolescent-compact",
      "metadata": {
        "id": "adolescent-compact"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lined-barrel",
      "metadata": {
        "id": "lined-barrel"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "answering-nelson",
      "metadata": {
        "id": "answering-nelson"
      },
      "source": [
        "> **EXERCISE**: Write a function `predict_input` which can make predictions for a single input provided as a dictionary. Make sure to include all the feature engineering and preprocessing steps. Refer to previous tutorials for hints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "drawn-picnic",
      "metadata": {
        "id": "drawn-picnic"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "veterinary-cattle",
      "metadata": {
        "id": "veterinary-cattle"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ranking-german",
      "metadata": {
        "id": "ranking-german"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "embedded-upset",
      "metadata": {
        "id": "embedded-upset"
      },
      "source": [
        "## Summary and References\n",
        "\n",
        "![](https://miro.medium.com/max/560/1*85QHtH-49U7ozPpmA5cAaw.png)\n",
        "\n",
        "The following topics were covered in this tutorial:\n",
        "\n",
        "- Downloading a real-world dataset from a Kaggle competition\n",
        "- Performing feature engineering and prepare the dataset for training\n",
        "- Training and interpreting a gradient boosting model using XGBoost\n",
        "- Training with KFold cross validation and ensembling results\n",
        "- Configuring the gradient boosting model and tuning hyperparamters\n",
        "\n",
        "Check out these resources to learn more:\n",
        "\n",
        "- https://albertum.medium.com/l1-l2-regularization-in-xgboost-regression-7b2db08a59e0\n",
        "- https://machinelearningmastery.com/evaluate-gradient-boosting-models-xgboost-python/\n",
        "- https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor\n",
        "- https://xgboost.readthedocs.io/en/latest/parameter.html\n",
        "- https://www.kaggle.com/xwxw2929/rossmann-sales-top1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ea8c8db",
      "metadata": {
        "id": "0ea8c8db"
      },
      "source": [
        "## Revision Questions\n",
        "1.\tWhat is a Gradient Boosting Machine (GBM) model?\n",
        "2.\tWhat does term ‘gradient’ refer to?\n",
        "3.\tWhat does term ‘boosting’ refer to?\n",
        "4.\tWhat are weights and bias?\n",
        "5.\tHow to choose differentiate/choose numerical and categorical columns?\n",
        "6.\tWhy do you scale numerical columns?\n",
        "7.\tWhy do you encode categorical columns?\n",
        "8.\tWhat is rankdir in <code>plot_tree()</code>?\n",
        "9.\tWhat is the working of K-fold cross validation?\n",
        "10.\tHow does gamma hyperparameter work?\n",
        "11.\tWhat is generalization?\n",
        "12.\tWhat is ensembling?\n",
        "13.\tWhat are the different ways to impute missing data?\n",
        "14.\tWhat are the advantages of XGBoost?\n",
        "15.\tWhat are the disadvantages of XGBoost?\n",
        "16.\tWhat are the data pre-processing steps for XGBoost?\n",
        "17.\tWhat is <code>rcParams</code>?\n",
        "18.\tWhat does <code>get_dump()</code> do?\n",
        "19.\tWhat is the difference between XGBoost and LightGBM?\n",
        "20.\tIs XGBoost faster than Random Forest? If so, why?"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}