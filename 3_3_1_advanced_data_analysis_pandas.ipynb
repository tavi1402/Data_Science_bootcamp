{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tavi1402/Data_Science_bootcamp/blob/main/3_3_1_advanced_data_analysis_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c765bf6",
      "metadata": {
        "id": "0c765bf6"
      },
      "source": [
        "# Advanced Data Analysis Techniques with Python & Pandas\n",
        "\n",
        "This tutorial is a part of the [Zero to Data Science Bootcamp by Jovian](https://zerotodatascience.com).\n",
        "\n",
        "![](https://i.imgur.com/jspPDKJ.png)\n",
        "\n",
        "Pandas is a popular Python library used for working in tabular data (similar to the data stored in a spreadsheet). Pandas offers several easy-to-use and efficient utilities for loading, processing, cleaning and analyzing large tabular datasets. Datasets containing millions of records can be processed using Pandas in a matter of minutes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6194b46e",
      "metadata": {
        "id": "6194b46e"
      },
      "source": [
        "This tutorial covers the following topics:\n",
        "\n",
        "- Downloading datasets from online sources\n",
        "- Processing massive datasets using Pandas\n",
        "- Working with categorical data\n",
        "- Handling missing and duplicate data\n",
        "- Transforming data with type-specific functions\n",
        "- Data frame concatenation and merging"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b3496a3",
      "metadata": {
        "id": "8b3496a3"
      },
      "source": [
        "### How to run the code\n",
        "\n",
        "This tutorial is an executable [Jupyter notebook](https://jupyter.org) hosted on [Jovian](https://www.jovian.ai). You can _run_ this tutorial and experiment with the code examples in a couple of ways: *using free online resources* (recommended) or *on your computer*.\n",
        "\n",
        "#### Option 1: Running using free online resources (1-click, recommended)\n",
        "\n",
        "The easiest way to start executing the code is to click the **Run** button at the top of this page and select **Run on Colab**. [Follow these instructions](https://jovian.ai/docs/user-guide/run.html#run-on-colab) to connect your Google Drive with Jovian.\n",
        "\n",
        "\n",
        "#### Option 2: Running on your computer locally\n",
        "\n",
        "To run the code on your computer locally, you'll need to set up [Python](https://www.python.org), download the notebook and install the required libraries. We recommend using the [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) distribution of Python. Click the **Run** button at the top of this page, select the **Run Locally** option, and follow the instructions.\n",
        "\n",
        ">  **Jupyter Notebooks**: This tutorial is a [Jupyter notebook](https://jupyter.org) - a document made of _cells_. Each cell can contain code written in Python or explanations in plain English. You can execute code cells and view the results, e.g., numbers, messages, graphs, tables, files, etc., instantly within the notebook. Jupyter is a powerful platform for experimentation and analysis. Don't be afraid to mess around with the code & break things - you'll learn a lot by encountering and fixing errors. You can use the \"Kernel > Restart & Clear Output\" menu option to clear all outputs and start again from the top."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb01c089",
      "metadata": {
        "id": "fb01c089"
      },
      "source": [
        "Let's install and import the required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be28a02",
      "metadata": {
        "id": "7be28a02"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VVKSvQtENQTs",
      "metadata": {
        "id": "VVKSvQtENQTs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b88291",
      "metadata": {
        "id": "c9b88291"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "eb28266e",
      "metadata": {
        "id": "eb28266e"
      },
      "source": [
        "## Finding and downloading datasets from online sources\n",
        "\n",
        "There are many great sources for finding datasets online:\n",
        "\n",
        "- [Kaggle datasets](http://kaggle.com/datasets)\n",
        "- [World Bank Open Data](https://data.worldbank.org)\n",
        "- [Yahoo Finance](https://finance.yahoo.com)\n",
        "- [Google Dataset Search](https://datasetsearch.research.google.com)\n",
        "- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.php)\n",
        "- [FastAI datasets](https://course.fast.ai/datasets)\n",
        "- and many more..\n",
        "\n",
        "While some of these provide public URLs to an easily downloadable dataset archive, others require login to limit abuse. As an example, let's look at Kaggle, which contains over 60,000+ community-curated datasets. We'll download the [US Accidents dataset](https://www.kaggle.com/sobhanmoosavi/us-accidents), which contains nearly 3 million records.\n",
        "\n",
        "**NOTE**: The `us-accidents` dataset is currently updated on the Kaggle and a part of it has been removed due to a request from one of the main traffic data providers. We've added **NOTE** for all the changes in the notebook.\n",
        "\n",
        "We can't use `requests` directly to download a dataset from Kaggle, because it doesn't provide a raw URL for the dataset. We'll use the `opendatasets` library, which can download a Kaggle dataset using an API token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c983dd0f",
      "metadata": {
        "id": "c983dd0f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "890b8e79",
      "metadata": {
        "id": "890b8e79"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "336412ea",
      "metadata": {
        "id": "336412ea"
      },
      "source": [
        "We'll use the `od.download` function to download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e49454fc",
      "metadata": {
        "id": "e49454fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dc60c04",
      "metadata": {
        "id": "7dc60c04"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99f15b88",
      "metadata": {
        "id": "99f15b88"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a937c169",
      "metadata": {
        "id": "a937c169"
      },
      "source": [
        "To download the dataset, you'll need to supply your Kaggle credentials, as explained here: https://github.com/jovianml/opendatasets#kaggle-credentials\n",
        "\n",
        "The data has been downloaded and unzipped to the folder `./us-accidents`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83def9bb",
      "metadata": {
        "id": "83def9bb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ea29c27b",
      "metadata": {
        "id": "ea29c27b"
      },
      "source": [
        "It consists of just one file, `US_Accidents_Dec20_updated.csv`, which is over 1 GB in size. We can also check the length of the file using the `wc` terminal command (only works on Linux and Mac).\n",
        "\n",
        "\n",
        "**NOTE**: The latest version of the `us-accidents` dataset is over 500 MB in size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f00ae934",
      "metadata": {
        "id": "f00ae934"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e1451d76",
      "metadata": {
        "id": "e1451d76"
      },
      "source": [
        "The file consists of over 2.9 million records! You can learn more about the dataset by reading the dataset description on Kaggle: https://www.kaggle.com/sobhanmoosavi/us-accidents .\n",
        "\n",
        "**NOTE**: The latest version of the `us-accidents` dataset has 1.5 million records.\n",
        "\n",
        "\n",
        "Try downloading a few other datasets from the sources listed above."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43c548be",
      "metadata": {
        "id": "43c548be"
      },
      "source": [
        "> **EXERCISE**: Find and a download a dataset providing country-wise population for the last 50 years. Use it to identify the countries with the highest percentage growth in population. What other insights can you gather from this data? Experiment with it in a new notebook.\n",
        ">\n",
        "> *Hint*: Visit https://data.worldbank.org .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0e555d4",
      "metadata": {
        "id": "f0e555d4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff7a0752",
      "metadata": {
        "id": "ff7a0752"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58e05d92",
      "metadata": {
        "id": "58e05d92"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7e0a7622",
      "metadata": {
        "id": "7e0a7622"
      },
      "source": [
        "> **EXERCISE**: Download the historical monthly stock price data for Apple Inc. (AAPL) since 1988. If you had bought Apple shares worth $100 Jan 1, 1991, what would they be worth on Jan 1, 2021? What other insights can you gather from this data? Experiment with it in a new notebook.\n",
        ">\n",
        "> *Hint*: Visit https://finance.yahoo.com ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b77c553",
      "metadata": {
        "id": "4b77c553"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f9769c",
      "metadata": {
        "id": "d8f9769c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa72a21",
      "metadata": {
        "id": "1aa72a21"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fde2695d",
      "metadata": {
        "id": "fde2695d"
      },
      "source": [
        "> **EXERCISE**: Learn about and download data set from https://archive.ics.uci.edu/ml/datasets/Air+quality . Show the trend of CO concentration using a line chart. What other insights can you gather from this data? Experiment with it in a new notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bdeed5d",
      "metadata": {
        "id": "5bdeed5d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ed5d997",
      "metadata": {
        "id": "6ed5d997"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a5b2d1a",
      "metadata": {
        "id": "2a5b2d1a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b7a6079",
      "metadata": {
        "id": "4b7a6079"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b18083dd",
      "metadata": {
        "id": "b18083dd"
      },
      "source": [
        "## Processing massive datasets using Pandas\n",
        "\n",
        "Let's load the US accidents data into a Pandas dataframe, and track the amount of time it takes using the `%%time` Jupyter magic command."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8b44465",
      "metadata": {
        "id": "d8b44465"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e190f12",
      "metadata": {
        "id": "9e190f12"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5290250e",
      "metadata": {
        "id": "5290250e"
      },
      "source": [
        "While the exact time for this operation depends on the hardware configuration of your computer, you will likely find that it takes less than a minute for Pandas to process a 1.1 GB containing over 2.9 million records. Isn't that impressive?\n",
        "\n",
        "**NOTE**: The latest version of the `us-accidents` dataset is over 500 MB in size containing over 1.5 million records.\n",
        "\n",
        "Let's take a look at the first few rows, and gather some information about the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fc7927a",
      "metadata": {
        "id": "4fc7927a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31f18cd4",
      "metadata": {
        "id": "31f18cd4",
        "scrolled": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "63d2ffbe",
      "metadata": {
        "id": "63d2ffbe"
      },
      "source": [
        "The dataset contains 2.9 million rows, 46 columns and occupies 790 MB of memory (RAM). Let's look at some strategies to load the data faster and use less memory.\n",
        "\n",
        "**NOTE**: The latest version of the `us-accidents` contains 1.5 million rows, 46 columns and occupies 412 MB of memory (RAM)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb689701",
      "metadata": {
        "id": "eb689701"
      },
      "source": [
        "### Load only the required columns\n",
        "\n",
        "You can provide the `usecols` argument to `read_csv` create a dataframe with just the given columns. This reduces the loading time, and uses lesser memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9dc02af",
      "metadata": {
        "id": "f9dc02af"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cee7883",
      "metadata": {
        "id": "3cee7883"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e109b778",
      "metadata": {
        "id": "e109b778",
        "scrolled": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "790136be",
      "metadata": {
        "id": "790136be"
      },
      "source": [
        "We've reduced the load time by over 40% and the memory usage by over 60%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "963f15cd",
      "metadata": {
        "id": "963f15cd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b8adcf35",
      "metadata": {
        "id": "b8adcf35"
      },
      "source": [
        "### Use smaller data types\n",
        "\n",
        "By default, Pandas uses large datatypes like `int64` and `float64` for numerical data. However, in many cases the data in the CSV file can be represented using a smaller data type such as `int32`, `float32`, `int16` etc.\n",
        "\n",
        "Date columns can be specified using the `parse_dates` argument.\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a40c0969",
      "metadata": {
        "id": "a40c0969"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5ccaefd",
      "metadata": {
        "id": "f5ccaefd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f99633b3",
      "metadata": {
        "id": "f99633b3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4ef6b429",
      "metadata": {
        "id": "4ef6b429"
      },
      "source": [
        "The load time and memory gains depend on the nature of the dataset. In this case, it leads to a 25% reduction in memory usage, with about the same load time. However, keep in mind that we no longer need to parse dates columns separately, which itself would take a few seconds for this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0988f991",
      "metadata": {
        "id": "0988f991"
      },
      "source": [
        "> **EXERCISE**: Parse the `Start_Time` and `End_Time` columns of `accidents_df2` as dates using `pd.to_datetime`. Measure the time taken for the conversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7c1165c",
      "metadata": {
        "id": "d7c1165c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6c9ad7c3",
      "metadata": {
        "id": "6c9ad7c3"
      },
      "source": [
        "### Using binary formats for intermediate results\n",
        "\n",
        "Since CSVs are plain text files with no structure, they often take longer to read compared to other binary formats which recognize the tabular structure of the data. Files can be saved and loaded using the `feather` and `parquet` formats for memory efficiency and faster processing.\n",
        "\n",
        "Let's save `accidents_df` to the feather format and load it back. It requires the `pyarrow` library to be installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9dfd0d6",
      "metadata": {
        "id": "c9dfd0d6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9056be91",
      "metadata": {
        "id": "9056be91"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65aff85d",
      "metadata": {
        "id": "65aff85d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "80714650",
      "metadata": {
        "id": "80714650"
      },
      "source": [
        "The feather file is over 40% smaller than the CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73fb4ac1",
      "metadata": {
        "id": "73fb4ac1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c58452ee",
      "metadata": {
        "id": "c58452ee"
      },
      "source": [
        "Notice that reading a feather file is 60% faster compared to reading a CSV file.  It's a good idea to save the intermediate results of your analysis in the feather format, so that you can load the file faster and avoid recomputing results when you resume your work.\n",
        "\n",
        "Check out a comparison of the feather and parquet formats here: https://ursalabs.org/blog/2020-feather-v2/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "733bd335",
      "metadata": {
        "id": "733bd335"
      },
      "source": [
        "### Working with a sample\n",
        "\n",
        "When working with a large dataset, sometimes it's better to work with a sample to set up your notebook, and then repeat your analysis with the entire dataset, to save time. You can use the `nrows` argument to supply the number of rows to be read."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8839647",
      "metadata": {
        "id": "b8839647"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6a8a2098",
      "metadata": {
        "id": "6a8a2098"
      },
      "source": [
        "Reading the first 1000 rows takes just a few milliseconds."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3431d11f",
      "metadata": {
        "id": "3431d11f"
      },
      "source": [
        "### Using dask for parallelism and memory efficiency\n",
        "\n",
        "Dask uses parallel processing to speed up data loading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3134c65c",
      "metadata": {
        "id": "3134c65c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a03fc85",
      "metadata": {
        "id": "0a03fc85"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d3ec998",
      "metadata": {
        "id": "8d3ec998"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "811ab6b2",
      "metadata": {
        "id": "811ab6b2"
      },
      "source": [
        "Many Pandas operations implemented using more efficient algorithms in dask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d724e241",
      "metadata": {
        "id": "d724e241"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6ec27433",
      "metadata": {
        "id": "6ec27433"
      },
      "source": [
        "To compute the memory usage, we need to provide `memory_usage=True`. Warning: This may take a while."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c823b12",
      "metadata": {
        "id": "7c823b12"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "32d4f05c",
      "metadata": {
        "id": "32d4f05c"
      },
      "source": [
        "Keep in mind that dask has a slightly different API compared to Pandas, and not all Pandas functions will work the same way. Check out the documentation of Dask to learn more: https://docs.dask.org/en/latest/dataframe.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d5e2b7",
      "metadata": {
        "id": "52d5e2b7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b29af05",
      "metadata": {
        "id": "4b29af05"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39247134",
      "metadata": {
        "id": "39247134"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a192cd75",
      "metadata": {
        "id": "a192cd75"
      },
      "source": [
        "> **EXERCISE**: List the various file types supported by Pandas for reading & writing. Demonstrate their usage with some examples. Use the official documentation for reference: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9527711",
      "metadata": {
        "id": "c9527711"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cccac33",
      "metadata": {
        "id": "5cccac33"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d83f86",
      "metadata": {
        "id": "27d83f86"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2182f009",
      "metadata": {
        "id": "2182f009"
      },
      "source": [
        "> **EXERCISE**: Save the contents of `accidents_df3` into various file formats like CSV, JSON, Excel, SQLite, Parquet, Feather etc. and read the files back using Pandas. Compare the writing time, size of created file and reading time for different formats.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9828006",
      "metadata": {
        "id": "a9828006"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13b895a9",
      "metadata": {
        "id": "13b895a9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aefb4f4",
      "metadata": {
        "id": "2aefb4f4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7335f956",
      "metadata": {
        "id": "7335f956"
      },
      "source": [
        "> **EXERCISE**: Download the New York Taxi Fare Prediction dataset from https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data . Pick 7 columns of the dataset and save it to an efficient intermediate format. How much improvement can you achieve in the file size, memory usage and reading time using the techniques listed above?\n",
        ">\n",
        "> *Warning*: This dataset is quite large (> 10 GB after uncompressing). Make sure you have enough disk space while before downloading it, or use an online platform like Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e45cb8e4",
      "metadata": {
        "id": "e45cb8e4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f451e01",
      "metadata": {
        "id": "6f451e01"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33d16203",
      "metadata": {
        "id": "33d16203"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81c0498c",
      "metadata": {
        "id": "81c0498c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f0bdd048",
      "metadata": {
        "id": "f0bdd048"
      },
      "source": [
        "## Working with  Categorical Data\n",
        "\n",
        "Consider the `Weather_Condition` column of the `accidents_sample_df`. While the values in the column are strings, there are only a limited number of values or _categories_ that occur in the column. `Weather_Condition` is a _categorical column_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c71bfb0",
      "metadata": {
        "id": "3c71bfb0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ab0a3a",
      "metadata": {
        "id": "81ab0a3a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "aa2a8262",
      "metadata": {
        "id": "aa2a8262"
      },
      "source": [
        "We can list all the values in the column using the `.unique` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "362a7a21",
      "metadata": {
        "id": "362a7a21"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "aa7b5256",
      "metadata": {
        "id": "aa7b5256"
      },
      "source": [
        "To check the number of unique values, use `nunique`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a41c9bfb",
      "metadata": {
        "id": "a41c9bfb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d99bbfda",
      "metadata": {
        "id": "d99bbfda"
      },
      "source": [
        "We can see the no. of occurrences of each value using `.value_counts()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa57c7a4",
      "metadata": {
        "id": "aa57c7a4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "65db3cb9",
      "metadata": {
        "id": "65db3cb9"
      },
      "source": [
        "We can convert the string column to a categorical column in Pandas by changing its data type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e23cd68f",
      "metadata": {
        "id": "e23cd68f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a99fda9",
      "metadata": {
        "id": "4a99fda9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d8c373ff",
      "metadata": {
        "id": "d8c373ff"
      },
      "source": [
        "While there's no visible change, the conversion allows Pandas to optimize the storage & querying for the column by representing each category internally using a numeric code.\n",
        "\n",
        "We can view the codes for each row as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41205968",
      "metadata": {
        "id": "41205968"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "75a2aede",
      "metadata": {
        "id": "75a2aede"
      },
      "source": [
        "The category code is the index of the category in the following list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee7cba0",
      "metadata": {
        "id": "bee7cba0",
        "scrolled": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a877beb5",
      "metadata": {
        "id": "a877beb5"
      },
      "source": [
        "Categorical columns are often replaced with their numeric codes before passing data into a machine learning algorithm which can only work with numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c4dd154",
      "metadata": {
        "id": "4c4dd154"
      },
      "source": [
        "### Numeric Categorical Columns\n",
        "\n",
        "The column `Severity` consists of categories too, even though its values are numeric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f71c55e",
      "metadata": {
        "id": "4f71c55e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0bf8a5a4",
      "metadata": {
        "id": "0bf8a5a4"
      },
      "source": [
        "Let's convert it into a categorical column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d53e5017",
      "metadata": {
        "id": "d53e5017"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed595c2c",
      "metadata": {
        "id": "ed595c2c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bda560ed",
      "metadata": {
        "id": "bda560ed"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d7537cd6",
      "metadata": {
        "id": "d7537cd6"
      },
      "source": [
        "### One Hot Encoding\n",
        "\n",
        "![](https://i.imgur.com/n8GuiOO.png)\n",
        "\n",
        "Sometimes it's useful to create a new column for each category of a categorical column, and set the value in the column to `1` if row belongs to the category and `0` otherwise. This technique is known as one-hot encoding and is commonly applied before passing data into machine learning algorithms.\n",
        "\n",
        "We can use the `pd.get_dummies` function to create a new column for each category of a categorical column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f82771d",
      "metadata": {
        "id": "2f82771d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "780ead17",
      "metadata": {
        "id": "780ead17"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3aa2a4fa",
      "metadata": {
        "id": "3aa2a4fa"
      },
      "source": [
        "The new columns can be added to the original data frame using the `pd.concat` method (we'll learn more about it later)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "091cfdaf",
      "metadata": {
        "id": "091cfdaf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "97bba64e",
      "metadata": {
        "id": "97bba64e"
      },
      "source": [
        "> **EXERICSE**: Repeat the aboves steps with `accidents_df` and `accidents_dask_df`. Track and compare the times taken for each operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbb5c003",
      "metadata": {
        "id": "bbb5c003"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66baac9f",
      "metadata": {
        "id": "66baac9f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d473b44f",
      "metadata": {
        "id": "d473b44f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9195c95b",
      "metadata": {
        "id": "9195c95b"
      },
      "source": [
        "> **EXERCISE**: Perform one-hot encoding for the `Weather_Condition` column of the dataframe `accidents_df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29dcea2b",
      "metadata": {
        "id": "29dcea2b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87fc05e5",
      "metadata": {
        "id": "87fc05e5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a3521c",
      "metadata": {
        "id": "06a3521c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "70e14cc0",
      "metadata": {
        "id": "70e14cc0"
      },
      "source": [
        "Learn more about working with categorical data in Pandas here: https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c032ddf",
      "metadata": {
        "id": "4c032ddf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "581c38d5",
      "metadata": {
        "id": "581c38d5"
      },
      "source": [
        "## Handling missing & duplicate data\n",
        "\n",
        "Missing data in Pandas is indicated using `np.nan`. We can find the number of missing values in each column of a dataframe using the following expression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1db2a5d0",
      "metadata": {
        "id": "1db2a5d0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d2b62285",
      "metadata": {
        "id": "d2b62285"
      },
      "source": [
        "The `End_Lat` and `End_Lng` columns have 96 missing values, and the `Weather_Condition` column has 21 missing values.\n",
        "\n",
        "**NOTE**: The latest version of the `us-accidents` dataset has no missing values in the `End_Lat` and `End_Lng` columns. Only the `Weather_Condition` column has 9 missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c7eca4b",
      "metadata": {
        "id": "2c7eca4b"
      },
      "source": [
        "> **EXERCISE**: What is the output of the `isna` method of a Pandas data frame or series. Demonstrate with examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65e47cf9",
      "metadata": {
        "id": "65e47cf9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e662637",
      "metadata": {
        "id": "9e662637"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bf109369",
      "metadata": {
        "id": "bf109369"
      },
      "source": [
        "We have the following options for dealing with missing values in numerical columns:\n",
        "\n",
        "1. Leave them as is, if they won't affect your analysis\n",
        "2. Replace them with an average\n",
        "3. Replace them with some other fixed value\n",
        "4. Remove the rows containing missing values\n",
        "5. Use the values from other rows & columns to estimate the missing value (imputation)\n",
        "\n",
        "Here's how approach 4 can be applied:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0fe8596",
      "metadata": {
        "id": "a0fe8596"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a61e8fe5",
      "metadata": {
        "id": "a61e8fe5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ce71fe6a",
      "metadata": {
        "id": "ce71fe6a"
      },
      "source": [
        "> **EXERCISE**: Replace the missing values in the columns `End_Lng` and `End_Lat` using the average value in each column. Hint: Use the function `.fillna`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7804f64",
      "metadata": {
        "id": "e7804f64"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2fbb47a",
      "metadata": {
        "id": "d2fbb47a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4caa03ab",
      "metadata": {
        "id": "4caa03ab"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "971da614",
      "metadata": {
        "id": "971da614"
      },
      "source": [
        "For categorical columns, we have the following options for dealing with missing values:\n",
        "\n",
        "1. Leave them as is, if they won't affect your analysis\n",
        "2. Create a new category for missing values\n",
        "3. Replace them with the most frequent category (or by some other fixed value)\n",
        "4. Replace them & add a new binary column indicating whether the value was missing\n",
        "5. Replace the columns with one-hot encoded columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "218ffa81",
      "metadata": {
        "id": "218ffa81"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "879f5cb0",
      "metadata": {
        "id": "879f5cb0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "922f6652",
      "metadata": {
        "id": "922f6652"
      },
      "source": [
        "Let's apply technique 3 i.e. replace the null values with the most common value (the mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c26abfa9",
      "metadata": {
        "id": "c26abfa9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ea9b20c",
      "metadata": {
        "id": "7ea9b20c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0cfaa30",
      "metadata": {
        "id": "c0cfaa30"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df26dd19",
      "metadata": {
        "id": "df26dd19"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c86eb595",
      "metadata": {
        "id": "c86eb595"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2640abec",
      "metadata": {
        "id": "2640abec"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "607fd63d",
      "metadata": {
        "id": "607fd63d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc1f3dca",
      "metadata": {
        "id": "bc1f3dca"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "62ceaa5e",
      "metadata": {
        "id": "62ceaa5e"
      },
      "source": [
        "> **EXERCISE**: Apply the other techniques listed above to handle missing values in the dataframe `accidents_sample_df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1775ae5",
      "metadata": {
        "id": "f1775ae5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3530dc9",
      "metadata": {
        "id": "a3530dc9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "635019fb",
      "metadata": {
        "id": "635019fb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7dca5c79",
      "metadata": {
        "id": "7dca5c79"
      },
      "source": [
        "> **EXERCISE**: Repeat the operations performed in the above section with `accidents_df` and `accidents_dask_df`. Measure and compare the time taken for each operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cc0ef55",
      "metadata": {
        "id": "2cc0ef55"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e735d9b1",
      "metadata": {
        "id": "e735d9b1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1fa6925",
      "metadata": {
        "id": "d1fa6925"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3aee4a9",
      "metadata": {
        "id": "e3aee4a9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e86114f4",
      "metadata": {
        "id": "e86114f4"
      },
      "source": [
        "### Duplicate Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4fc39bf",
      "metadata": {
        "id": "b4fc39bf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4524be2",
      "metadata": {
        "id": "e4524be2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c725fe9a",
      "metadata": {
        "id": "c725fe9a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b24004da",
      "metadata": {
        "id": "b24004da"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a0376d88",
      "metadata": {
        "id": "a0376d88"
      },
      "source": [
        "If required, duplicate rows can be removed using the `.drop_duplicates` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23cd22d6",
      "metadata": {
        "id": "23cd22d6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "96ee162d",
      "metadata": {
        "id": "96ee162d"
      },
      "source": [
        "Think carefully about how the data was collected before removing duplicates. Removing duplicates may not always be the right approach."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "949447f5",
      "metadata": {
        "id": "949447f5"
      },
      "source": [
        "> **EXERCISE**: Check for duplicates in `accidents_df` and remove them if required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2bfb4b3",
      "metadata": {
        "id": "b2bfb4b3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13ab0efa",
      "metadata": {
        "id": "13ab0efa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "056a2e76",
      "metadata": {
        "id": "056a2e76"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f1471c02",
      "metadata": {
        "id": "f1471c02"
      },
      "source": [
        "> **EXERCISE**: Repeat the exercises in this section with `accidents_df` and `accidents_dask_df` and track the time taken by each operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "839214b9",
      "metadata": {
        "id": "839214b9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c776190",
      "metadata": {
        "id": "1c776190"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02325cbd",
      "metadata": {
        "id": "02325cbd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "680f77b4",
      "metadata": {
        "id": "680f77b4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "84f46e24",
      "metadata": {
        "id": "84f46e24"
      },
      "source": [
        "## Transforming and aggregating data with type-specific functions\n",
        "\n",
        "Pandas offers several methods for working with specific types of data. Additionally, we can also use Numpy functions to perform operations on Pandas series. Let's look at some utility methods by three types of data: numbers, strings and dates."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69f392c2",
      "metadata": {
        "id": "69f392c2"
      },
      "source": [
        "### Numbers\n",
        "\n",
        "Here are some functions useful for transforming and aggregating numeric data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4402b07f",
      "metadata": {
        "id": "4402b07f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01076fcd",
      "metadata": {
        "id": "01076fcd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bae6d2d2",
      "metadata": {
        "id": "bae6d2d2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5e65b5a",
      "metadata": {
        "id": "d5e65b5a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd6befe",
      "metadata": {
        "id": "9fd6befe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f431752a",
      "metadata": {
        "id": "f431752a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3c732fad",
      "metadata": {
        "id": "3c732fad"
      },
      "source": [
        "We can also apply numpy functions to Pandas series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "744d26b4",
      "metadata": {
        "id": "744d26b4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c349b629",
      "metadata": {
        "id": "c349b629"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bc34247",
      "metadata": {
        "id": "9bc34247"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "59ece071",
      "metadata": {
        "id": "59ece071"
      },
      "source": [
        "Pandas series also support arithmetic operators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19604cdf",
      "metadata": {
        "id": "19604cdf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab02ba93",
      "metadata": {
        "id": "ab02ba93"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dc5a472",
      "metadata": {
        "id": "4dc5a472"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1232b5bc",
      "metadata": {
        "id": "1232b5bc"
      },
      "source": [
        "> **EXERCISE**: Try out some more arithmetic operations with other numeric columns of `accidents_df` and `accidents_dask_df`. Measure and compare the time taken for each operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66300ef9",
      "metadata": {
        "id": "66300ef9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb7f2235",
      "metadata": {
        "id": "fb7f2235"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f170196",
      "metadata": {
        "id": "6f170196"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "88cb70a5",
      "metadata": {
        "id": "88cb70a5"
      },
      "source": [
        "### Strings\n",
        "\n",
        "The `.str` property of a Pandas series provides several utility functions for manipulating string data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4918474c",
      "metadata": {
        "id": "4918474c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8488c413",
      "metadata": {
        "id": "8488c413"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d44cc29f",
      "metadata": {
        "id": "d44cc29f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c68420d",
      "metadata": {
        "id": "1c68420d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5cc48ab",
      "metadata": {
        "id": "c5cc48ab"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f45825eb",
      "metadata": {
        "id": "f45825eb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cca18a5",
      "metadata": {
        "id": "4cca18a5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "13b475a1",
      "metadata": {
        "id": "13b475a1"
      },
      "source": [
        "> **EXERCISE**: Explore other string methods supported by Pandas data frames and series: https://pandas.pydata.org/docs/user_guide/text.html#string-methods . Demonstrate their usage with examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d96f5e0e",
      "metadata": {
        "id": "d96f5e0e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d8e6bb7",
      "metadata": {
        "id": "3d8e6bb7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0e5691e2",
      "metadata": {
        "id": "0e5691e2"
      },
      "source": [
        "### Date & Time\n",
        "\n",
        "The `.dt` property of a Pandas consists of utlity methods for working with dates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a4d0fc",
      "metadata": {
        "id": "31a4d0fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed5d444",
      "metadata": {
        "id": "eed5d444"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f8093e23",
      "metadata": {
        "id": "f8093e23"
      },
      "source": [
        "Let's extract different parts of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbfc7da5",
      "metadata": {
        "id": "bbfc7da5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3e60b2d",
      "metadata": {
        "id": "b3e60b2d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7a0fece",
      "metadata": {
        "id": "b7a0fece"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11395d87",
      "metadata": {
        "id": "11395d87"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c50e88bd",
      "metadata": {
        "id": "c50e88bd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "900b19f3",
      "metadata": {
        "id": "900b19f3"
      },
      "source": [
        "> **EXERCISE**: Explore other date methods supported by Pandas series: https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#basics-dt-accessors . Demonstrate their usage with examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54007fbf",
      "metadata": {
        "id": "54007fbf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "41ebb440",
      "metadata": {
        "id": "41ebb440"
      },
      "source": [
        "### `map` and `apply`\n",
        "\n",
        "The `map` method of a column/series can be used to apply a custom function to each element of a series. Let's use it to convert the distance from miles to kilometres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f972e630",
      "metadata": {
        "id": "f972e630"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69958275",
      "metadata": {
        "id": "69958275"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "af175c86",
      "metadata": {
        "id": "af175c86"
      },
      "source": [
        "The `apply` method  can be used to apply a custom function to each column/row of a dataframe. Let's use it to compute the duration of each event."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf6fcceb",
      "metadata": {
        "id": "cf6fcceb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "419d8124",
      "metadata": {
        "id": "419d8124"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a82bd700",
      "metadata": {
        "id": "a82bd700"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94a6ea67",
      "metadata": {
        "id": "94a6ea67"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4d80a599",
      "metadata": {
        "id": "4d80a599"
      },
      "source": [
        "> **EXERCISE**: Look up the documentation for the `applymap` method of a data frame. How is it different from `apply` and `map` methods? Demonstrate with examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f4bbc5",
      "metadata": {
        "id": "28f4bbc5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bd27564",
      "metadata": {
        "id": "1bd27564"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b04394a1",
      "metadata": {
        "id": "b04394a1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e068ee2b",
      "metadata": {
        "id": "e068ee2b"
      },
      "source": [
        "> **EXERCISE**: Repeat the operations performed in this section (type-specific functions) with `accidents_df` and `accidents_dask_df`. Measure and compare the time taken for each operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "416aa04f",
      "metadata": {
        "id": "416aa04f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a046c230",
      "metadata": {
        "id": "a046c230"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f683e6a",
      "metadata": {
        "id": "6f683e6a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10b438d1",
      "metadata": {
        "id": "10b438d1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "14e3c72c",
      "metadata": {
        "id": "14e3c72c"
      },
      "source": [
        "Learn more about `map` and `apply` here: https://towardsdatascience.com/introduction-to-pandas-apply-applymap-and-map-5d3e044e93ff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd7578e9",
      "metadata": {
        "id": "fd7578e9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "be94ef82",
      "metadata": {
        "id": "be94ef82"
      },
      "source": [
        "## Data frame concatenation and merging\n",
        "\n",
        "Pandas provides various utilities for combining multiple data frames. We'll look at two examples in this section: concatenation and merging."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05140419",
      "metadata": {
        "id": "05140419"
      },
      "source": [
        "### Concatenation\n",
        "\n",
        "Concatenation is the process of stacking two more dataframes vertically or horizontally. When concatenating vertically, columns are lined up together. Here's what vertical concatenation looks like:\n",
        "\n",
        "![](https://i.imgur.com/ti195t3.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8361aff3",
      "metadata": {
        "id": "8361aff3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3a0be694",
      "metadata": {
        "id": "3a0be694"
      },
      "source": [
        "We can now concatenate these along axis 0 i.e. vertically using `pd.concat`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f99d69ec",
      "metadata": {
        "id": "f99d69ec"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f30053f7",
      "metadata": {
        "id": "f30053f7"
      },
      "source": [
        "This operation can also be performed using the `.append` method of a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4433fb5d",
      "metadata": {
        "id": "4433fb5d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "495a4c35",
      "metadata": {
        "id": "495a4c35"
      },
      "source": [
        "> **EXERCISE**: Remove the column `D` from `df3`. How does it affect the result of vertical concatenation? Try passing the argument `join=\"inner\"` to `pd.concat`. Do you observe any change?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6edc2339",
      "metadata": {
        "id": "6edc2339"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6761a6ce",
      "metadata": {
        "id": "6761a6ce"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "194f1b0f",
      "metadata": {
        "id": "194f1b0f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bc5cd0cf",
      "metadata": {
        "id": "bc5cd0cf"
      },
      "source": [
        "> **EXERCISE**: Create two dataframes that don't have any common columns and concatenate them vertically. What do you observe? Try providing the arguments `join=\"outer\"` and `join=\"inner\"`. How do they affect the results?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7aa77db7",
      "metadata": {
        "id": "7aa77db7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08c3dcd1",
      "metadata": {
        "id": "08c3dcd1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e409330f",
      "metadata": {
        "id": "e409330f"
      },
      "source": [
        "> **EXERCISE**: Explore the arguments supported by `pd.concat` and come up with some examples to demonstrate the purpose of each argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73879b9e",
      "metadata": {
        "id": "73879b9e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "282a0f33",
      "metadata": {
        "id": "282a0f33"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f99fb3d",
      "metadata": {
        "id": "7f99fb3d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8e0f62ee",
      "metadata": {
        "id": "8e0f62ee"
      },
      "source": [
        "Concatenation can also be performed horizontally by providing the argument `axis=1` to `pd.concat`. Rows are lined up together using the index.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79a2f717",
      "metadata": {
        "id": "79a2f717"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0316213f",
      "metadata": {
        "id": "0316213f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3eb9cad",
      "metadata": {
        "id": "f3eb9cad"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "248e7cbb",
      "metadata": {
        "id": "248e7cbb"
      },
      "source": [
        "`pd.concat` performs an \"outer\" join by default, which retains all the indexes from both data frames. An \"inner\" join only retains the common indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2be2d798",
      "metadata": {
        "id": "2be2d798"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fe177238",
      "metadata": {
        "id": "fe177238"
      },
      "source": [
        "Learn more about dataframe concatenation here: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#concatenating-objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87268c8",
      "metadata": {
        "id": "b87268c8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b02343d0",
      "metadata": {
        "id": "b02343d0"
      },
      "source": [
        "### Merging\n",
        "\n",
        "Two Pandas dataframes can be merged together row-wise using one more columns using the `.merge` method of a dataframe. A merge can be peformed in several ways:\n",
        "\n",
        "![](https://i.imgur.com/p2fXTFs.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcce5377",
      "metadata": {
        "id": "dcce5377"
      },
      "source": [
        "> **EXERCISE**: Demonstrate the four types of join listed above using the following dataframes. Use the `key` column for merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4455daf",
      "metadata": {
        "id": "d4455daf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83f94543",
      "metadata": {
        "id": "83f94543"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f53bb79",
      "metadata": {
        "id": "9f53bb79"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51137867",
      "metadata": {
        "id": "51137867"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66df3227",
      "metadata": {
        "id": "66df3227"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fecc935a",
      "metadata": {
        "id": "fecc935a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f86f690",
      "metadata": {
        "id": "4f86f690"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "837dc922",
      "metadata": {
        "id": "837dc922"
      },
      "source": [
        "> **EXERCISE**: Show an example of merging two dataframes on two columns.\n",
        ">\n",
        "> *Hint*: Read the docs: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a2f89c7",
      "metadata": {
        "id": "1a2f89c7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d0e23e4",
      "metadata": {
        "id": "8d0e23e4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d92d1e07",
      "metadata": {
        "id": "d92d1e07"
      },
      "source": [
        "> **EXERCISE**: Look up the documentation for the `pd.join` function. How is it different from `pd.merge`? Demonstrate with examples. Hint: A join is always performed on the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df0830f3",
      "metadata": {
        "id": "df0830f3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "386e89f6",
      "metadata": {
        "id": "386e89f6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a42a7e0d",
      "metadata": {
        "id": "a42a7e0d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c972a987",
      "metadata": {
        "id": "c972a987"
      },
      "source": [
        "## Summary and Further Reading\n",
        "\n",
        "We've covered the following topics in this tutorial:\n",
        "\n",
        "- Downloading datasets from online sources\n",
        "- Processing massive datasets using Pandas\n",
        "- Handling missing, incorrect & duplicate data\n",
        "- Transforming data with type-specific functions\n",
        "- Techniques for encoding categorical data\n",
        "- Concatenation, merging and comparison\n",
        "\n",
        "As an exercise, you can apply the above to other datasets, from the following sources:\n",
        "\n",
        "- [Kaggle datasets](http://kaggle.com/datasets)\n",
        "- [World Bank Open Data](https://data.worldbank.org)\n",
        "- [Yahoo Finance](https://finance.yahoo.com)\n",
        "- [Google Dataset Search](https://datasetsearch.research.google.com)\n",
        "- [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets.php)\n",
        "- [FastAI datasets](https://course.fast.ai/datasets)\n",
        "\n",
        "\n",
        "Check out the following resources to learn more:\n",
        "\n",
        "- Working with categorical data in Pandas: https://jovian.ai/himani007/categorical-data-with-pandas\n",
        "- Working with large datasets in Pandas: https://jovian.ai/himani007/pandas1-large-datasets\n",
        "- Python for Data Analysis: https://www.amazon.com/Python-Data-Analysis-Wrangling-IPython-ebook/dp/B075X4LT6K\n",
        "- Pandas API reference: https://pandas.pydata.org/pandas-docs/stable/reference/index.html\n",
        "- Merging Pandas dataframes: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\n",
        "- Advanced Pandas tutorial notebooks: https://www.kaggle.com/residentmario/welcome-to-advanced-pandas\n",
        "- Dask dataframes documentation: https://docs.dask.org/en/latest/dataframe.html\n",
        "- [How to load CSV files 10x faster and use 10x less memory](https://towardsdatascience.com/%EF%B8%8F-load-the-same-csv-file-10x-times-faster-and-with-10x-less-memory-%EF%B8%8F-e93b485086c7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3a39d11",
      "metadata": {
        "id": "b3a39d11"
      },
      "source": [
        "## Questions for Revision\n",
        "\n",
        "1.\tHow do you download a dataset from Kaggle?\n",
        "2.\tHow do you check length of the file on Windows?\n",
        "3.\tWhat is the purpose of `%%time`?\n",
        "4.\tWhat are the different methods and functions you can use to get information about the data in dataframe?\n",
        "5.\tHow to load only the required columns from a large dataset?\n",
        "6.\tWhat is the purpose of using smaller datatype?\n",
        "7.\tHow is `parse_dates` different from `pd.to_datetime`?\n",
        "8.\tWhat are the different formats one can use when loading CSV files for better memory efficiency and faster processing?\n",
        "9.\tHow does working with a sample of your data first help with analysis?\n",
        "10.\tWhat is dask?\n",
        "11.\tWhat is categorical data? How to deal with them during analysis?\n",
        "12.\tWhat is One Hot Encoding?\n",
        "13.\tWhat are the different techniques to handle missing values?\n",
        "14.\tWhy should one be careful when removing duplicates from the data?\n",
        "15.\tWhat are the different methods you can use on numeric, string, and date type data?\n",
        "16.\tHow is `map()` different from `apply()`?\n",
        "17.\tWhat is `applymap()`?\n",
        "18.\tWhat is axis parameter in Pandas?\n",
        "19.\tHow do `join='inner'` and `join='outer'` work?\n",
        "20.\tWhat are the several ways to perform `merge()`?\n",
        "21.\tWhat is `on` parameter in `merge()`?\n",
        "22.\tHow is `concate()` different from `merge()`?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12dcdf97",
      "metadata": {
        "id": "12dcdf97"
      },
      "source": [
        "## Solutions for Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfd8abf9",
      "metadata": {
        "id": "bfd8abf9"
      },
      "source": [
        "> **EXERCISE**: Find and a download a dataset providing country-wise population for the last 50 years. Use it to identify the countries with the highest percentage growth in population. What other insights can you gather from this data? Experiment with it in a new notebook.\n",
        ">\n",
        "> *Hint*: Visit https://data.worldbank.org .\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cc06203",
      "metadata": {
        "id": "3cc06203"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30ee4d6d",
      "metadata": {
        "id": "30ee4d6d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73047699",
      "metadata": {
        "id": "73047699"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2930d072",
      "metadata": {
        "id": "2930d072"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ca9659d",
      "metadata": {
        "id": "6ca9659d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8994703",
      "metadata": {
        "id": "f8994703"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9d81bb60",
      "metadata": {
        "id": "9d81bb60"
      },
      "source": [
        "**OBSERVATION**: Middle East countries UAE, Qatar, Bahrain seem to take the top positions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c04ed98f",
      "metadata": {
        "id": "c04ed98f"
      },
      "source": [
        "Other insights that we can gather from this data:\n",
        " - Countries with the least percentage growth in population.\n",
        " - Was the pandemic during 2019-2020 affecting the population growth?\n",
        " - Merge the `population` data with `birth` and `death` data to identify the counrties with rapid population growth.\n",
        " - Merge the `population` data with `gender` data to calculate the gender ratio among the countries.\n",
        " - Plot the distribution of different country's population."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f84fa02c",
      "metadata": {
        "id": "f84fa02c"
      },
      "source": [
        "> **EXERCISE**: Download the historical monthly stock price data for Apple Inc. (AAPL) since 1988. If you had bought Apple shares worth $100 Jan 1, 1991, what would they be worth on Jan 1, 2021? What other insights can you gather from this data? Experiment with it in a new notebook.\n",
        ">\n",
        "> *Hint*: Visit https://finance.yahoo.com ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0952ee07",
      "metadata": {
        "id": "0952ee07"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2f14ed4",
      "metadata": {
        "id": "b2f14ed4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08d0b4e0",
      "metadata": {
        "id": "08d0b4e0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd51c0b",
      "metadata": {
        "id": "5dd51c0b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90027506",
      "metadata": {
        "id": "90027506"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77f0f079",
      "metadata": {
        "id": "77f0f079"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a24f6ac6",
      "metadata": {
        "id": "a24f6ac6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "495e6e8c",
      "metadata": {
        "id": "495e6e8c"
      },
      "source": [
        "**OBSERVATION**: That's more than 10 times the actual price!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58fed800",
      "metadata": {
        "id": "58fed800"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2b7fc29f",
      "metadata": {
        "id": "2b7fc29f"
      },
      "source": [
        "Other insights that we can gather from this data:\n",
        " - Highest price the stock reached in a month, year.\n",
        " - Lowest price the stock traded in a month, year.\n",
        " - Total amount of stocks traded (volume) in a month, year.\n",
        " - Calculate the moving average of the prices and plot their trend."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b09ea62a",
      "metadata": {
        "id": "b09ea62a"
      },
      "source": [
        "> **EXERCISE**: Learn about and download data set from https://archive.ics.uci.edu/ml/datasets/Air+quality . Show the trend of CO concentration using a line chart. What other insights can you gather from this data? Experiment with it in a new notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43861c8a",
      "metadata": {
        "id": "43861c8a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab2f1fef",
      "metadata": {
        "id": "ab2f1fef"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f299f260",
      "metadata": {
        "id": "f299f260"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83f155ed",
      "metadata": {
        "id": "83f155ed"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5925038",
      "metadata": {
        "id": "c5925038"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6499489c",
      "metadata": {
        "id": "6499489c"
      },
      "source": [
        "- Looks weird, doesn't it? Let's go through the data sest information to understand the data better."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3df6f9cb",
      "metadata": {
        "id": "3df6f9cb"
      },
      "source": [
        "![](https://i.imgur.com/IV4NGp8.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f39a004",
      "metadata": {
        "id": "3f39a004"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53c50d7d",
      "metadata": {
        "id": "53c50d7d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "208fecf6",
      "metadata": {
        "id": "208fecf6"
      },
      "source": [
        "**OBSERVATION**: Nov, Dec of 2004 seem to record the highest average CO concentration."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab4837a5",
      "metadata": {
        "id": "ab4837a5"
      },
      "source": [
        "Other insights that we can gather from this data:\n",
        " - Show the trends of different gases.\n",
        " - Plot the gases with time on an axis to see which time of the day records highest and lowest values.\n",
        " - Check for correlation between the gases, if there is a high correlation between any gases, find out the reason."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41bcd708",
      "metadata": {
        "id": "41bcd708"
      },
      "source": [
        "> **EXERCISE**: Parse the `Start_Time` and `End_Time` columns of `accidents_df2` as dates using `pd.to_datetime`. Measure the time taken for the conversion."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b19a47c",
      "metadata": {
        "id": "5b19a47c"
      },
      "source": [
        "**NOTE**: The time for these operations may vary from person to person as they depend on the hardware configuration of the computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2e8e64",
      "metadata": {
        "id": "bd2e8e64"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c037a92",
      "metadata": {
        "id": "7c037a92"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "53a4c9b4",
      "metadata": {
        "id": "53a4c9b4"
      },
      "source": [
        "**OBSERVATION**: The time taken for converting `Start_Time` and `End_Time` separately using `pd.to_datetime` is 1.03 s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed4ee105",
      "metadata": {
        "id": "ed4ee105"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "781c04db",
      "metadata": {
        "id": "781c04db"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "25ea0633",
      "metadata": {
        "id": "25ea0633"
      },
      "source": [
        "**OBSERVATION**: The time taken for converting `Start_Time` and `End_Time` together using `pd.to_datetime` and `.apply()` is 958 ms."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7dc03a0",
      "metadata": {
        "id": "f7dc03a0"
      },
      "source": [
        "> **EXERCISE**: List the various file types supported by Pandas for reading & writing. Demonstrate their usage with some examples. Use the official documentation for reference: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c276adcf",
      "metadata": {
        "id": "c276adcf"
      },
      "source": [
        "- Link for an article - https://realpython.com/pandas-read-write-files/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "659b1e46",
      "metadata": {
        "id": "659b1e46"
      },
      "source": [
        "> **EXERCISE**: Save the contents of `accidents_df3` into various file formats like CSV, JSON, Excel, SQLite, Parquet, Feather etc. and read the files back using Pandas. Compare the writing time, size of created file and reading time for different formats.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6114ecfe",
      "metadata": {
        "id": "6114ecfe"
      },
      "source": [
        "**NOTE**: The time for these operations may vary from person to person as they depend on the hardware configuration of the computer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6edb8676",
      "metadata": {
        "id": "6edb8676"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c229e6e3",
      "metadata": {
        "id": "c229e6e3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4f5c999",
      "metadata": {
        "id": "e4f5c999"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "738ad35f",
      "metadata": {
        "id": "738ad35f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66a8051e",
      "metadata": {
        "id": "66a8051e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c8cbd6",
      "metadata": {
        "id": "61c8cbd6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e44a0573",
      "metadata": {
        "id": "e44a0573"
      },
      "source": [
        "- Pandas was throwing an [error](https://stackoverflow.com/questions/47076719/saving-big-xlsx-files-pandas-python) when converting the entire dataframe so we'll pick a sample with the maximum size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68d7c83b",
      "metadata": {
        "id": "68d7c83b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffcd81bc",
      "metadata": {
        "id": "ffcd81bc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b9b8cb5",
      "metadata": {
        "id": "2b9b8cb5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd9fc1d4",
      "metadata": {
        "id": "cd9fc1d4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "315dac07",
      "metadata": {
        "id": "315dac07"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd202ba",
      "metadata": {
        "id": "bbd202ba"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c60410c2",
      "metadata": {
        "id": "c60410c2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc216332",
      "metadata": {
        "id": "fc216332"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3a076f9",
      "metadata": {
        "id": "b3a076f9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8684f43",
      "metadata": {
        "id": "a8684f43"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b19b2ad",
      "metadata": {
        "id": "5b19b2ad"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ab8029c",
      "metadata": {
        "id": "2ab8029c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "505ad1c0",
      "metadata": {
        "id": "505ad1c0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5523d87f",
      "metadata": {
        "id": "5523d87f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fef0b7cb",
      "metadata": {
        "id": "fef0b7cb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9e1babba",
      "metadata": {
        "id": "9e1babba"
      },
      "source": [
        "**OBSERVATION**: `to_feather()` and `read_feather` took the least amount of time for conversion."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1486d76",
      "metadata": {
        "id": "f1486d76"
      },
      "source": [
        "> **EXERCISE**: Download the New York Taxi Fare Prediction dataset from https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data . Pick 7 columns of the dataset and save it to an efficient intermediate format. How much improvement can you achieve in the file size, memory usage and reading time using the techniques listed above?\n",
        ">\n",
        "> *Warning*: This dataset is quite large (> 10 GB after uncompressing). Make sure you have enough disk space while before downloading it, or use an online platform like Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb27766f",
      "metadata": {
        "id": "bb27766f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50053734",
      "metadata": {
        "id": "50053734"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50a22039",
      "metadata": {
        "id": "50a22039"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae279f6c",
      "metadata": {
        "id": "ae279f6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a395b08",
      "metadata": {
        "id": "8a395b08"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ca22e4b",
      "metadata": {
        "id": "1ca22e4b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f298a6d2",
      "metadata": {
        "id": "f298a6d2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "affc2b59",
      "metadata": {
        "id": "affc2b59"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6240c724",
      "metadata": {
        "id": "6240c724"
      },
      "source": [
        "**OBSERVATION**: `pd.read_csv()` is faster in reading when compared to `pd.read_feather` or `pd.read_parquet`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0670036",
      "metadata": {
        "id": "c0670036"
      },
      "source": [
        "> **EXERICSE**: Repeat the aboves steps with `accidents_df` and `accidents_dask_df`. Track and compare the times taken for each operation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e1ac27a",
      "metadata": {
        "id": "2e1ac27a"
      },
      "source": [
        "**NOTE**: The time for these operations may vary from person to person as they depend on the hardware configuration of the computer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef1b3aac",
      "metadata": {
        "id": "ef1b3aac"
      },
      "source": [
        "`accidents_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b670261e",
      "metadata": {
        "id": "b670261e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24f88eac",
      "metadata": {
        "id": "24f88eac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85a393ba",
      "metadata": {
        "id": "85a393ba"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc27f317",
      "metadata": {
        "id": "cc27f317"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25470844",
      "metadata": {
        "id": "25470844"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7c8f6c8",
      "metadata": {
        "id": "b7c8f6c8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9447b452",
      "metadata": {
        "id": "9447b452"
      },
      "source": [
        "**OBSERVATION**: As the size increase the time taken for conversion has also increased."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27a1b9cd",
      "metadata": {
        "id": "27a1b9cd"
      },
      "source": [
        "`accidents_dask_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6505f226",
      "metadata": {
        "id": "6505f226"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f4648a4",
      "metadata": {
        "id": "0f4648a4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4ad5aa9",
      "metadata": {
        "id": "f4ad5aa9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c81cee2",
      "metadata": {
        "id": "5c81cee2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42af4c15",
      "metadata": {
        "id": "42af4c15"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a4083bc",
      "metadata": {
        "id": "5a4083bc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecd3393f",
      "metadata": {
        "id": "ecd3393f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d761464",
      "metadata": {
        "id": "4d761464"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "88c4213f",
      "metadata": {
        "id": "88c4213f"
      },
      "source": [
        "> **EXERCISE**: Perform one-hot encoding for the `Weather_Condition` column of the dataframe `accidents_df`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41de6508",
      "metadata": {
        "id": "41de6508"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe8bb4ea",
      "metadata": {
        "id": "fe8bb4ea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13a002c",
      "metadata": {
        "id": "a13a002c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5b369ecc",
      "metadata": {
        "id": "5b369ecc"
      },
      "source": [
        "> **EXERCISE**: What is the output of the `isna` method of a Pandas data frame or series. Demonstrate with examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2961b913",
      "metadata": {
        "id": "2961b913"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d0878f57",
      "metadata": {
        "id": "d0878f57"
      },
      "source": [
        "**OBSERVATION**: `.isna()` is function used to identify the missing values in a dataframe. The function returns a dataframe with boolean values `True` or `False`. `True` indicates the presence of missing values such a `NA` or `NaN`. `False` indicates the presence of a value."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0688385c",
      "metadata": {
        "id": "0688385c"
      },
      "source": [
        "We have the following options for dealing with missing values in numerical columns:\n",
        "\n",
        "1. Leave them as is, if they won't affect your analysis\n",
        "2. Replace them with an average\n",
        "3. Replace them with some other fixed value\n",
        "4. Remove the rows containing missing values\n",
        "5. Use the values from other rows & columns to estimate the missing value (imputation)\n",
        "\n",
        "Here's how approach 4 can be applied:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3676a05c",
      "metadata": {
        "id": "3676a05c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2fbc722",
      "metadata": {
        "id": "e2fbc722"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b16658af",
      "metadata": {
        "id": "b16658af"
      },
      "source": [
        "> **EXERCISE**: Replace the missing values in the columns `End_Lng` and `End_Lat` using the average value in each column. Hint: Use the function `.fillna`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85d221d9",
      "metadata": {
        "id": "85d221d9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80a42b04",
      "metadata": {
        "id": "80a42b04"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "178a199d",
      "metadata": {
        "id": "178a199d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec1492de",
      "metadata": {
        "id": "ec1492de"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "16c4f5a1",
      "metadata": {
        "id": "16c4f5a1"
      },
      "source": [
        "Let's apply technique 3 i.e. replace the null values with the most common value (the mode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5f4da1c",
      "metadata": {
        "id": "f5f4da1c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ff51386",
      "metadata": {
        "id": "2ff51386"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fb5af62",
      "metadata": {
        "id": "6fb5af62"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1998f8f",
      "metadata": {
        "id": "c1998f8f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6824ab4b",
      "metadata": {
        "id": "6824ab4b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9431b0ea",
      "metadata": {
        "id": "9431b0ea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26479206",
      "metadata": {
        "id": "26479206"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de2f928e",
      "metadata": {
        "id": "de2f928e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1fd21dfb",
      "metadata": {
        "id": "1fd21dfb"
      },
      "source": [
        "> **EXERCISE**: Apply the other techniques listed above to handle missing values in the dataframe `accidents_sample_df`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8537b77a",
      "metadata": {
        "id": "8537b77a"
      },
      "source": [
        "Let's apply technique 4 i.e. Replace them & add a new binary column indicating whether the value was missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c4b2ca8",
      "metadata": {
        "id": "6c4b2ca8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ba2e2a2",
      "metadata": {
        "id": "9ba2e2a2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcfa2e3e",
      "metadata": {
        "id": "bcfa2e3e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360ee274",
      "metadata": {
        "id": "360ee274"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e55c4833",
      "metadata": {
        "id": "e55c4833"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "290a94ce",
      "metadata": {
        "id": "290a94ce"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1668a5bc",
      "metadata": {
        "id": "1668a5bc"
      },
      "source": [
        "> **EXERCISE**: Repeat the operations performed in the above section with `accidents_df` and `accidents_dask_df`. Measure and compare the time taken for each operation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a48c7f6",
      "metadata": {
        "id": "3a48c7f6"
      },
      "source": [
        "- `accidents_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20954c83",
      "metadata": {
        "id": "20954c83"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "039c659c",
      "metadata": {
        "id": "039c659c"
      },
      "source": [
        "That's a lot of missing values, huh?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "002f85d7",
      "metadata": {
        "id": "002f85d7"
      },
      "source": [
        "Here's what we will do for the columns with missing values:\n",
        "- Technique 1 i.e. Leave them as is, if they won't affect your analysis for `Number`, `zipcode`, `Airport_Code`, `Timezone` and `Weather_Timestamp` columns as they don't affect our analysis.\n",
        "- Technique 2 i.e. Create a new category for missing values for `city` column with missing value as `unknown` category\n",
        "- Technique 3 i.e. Replace them with the most frequent category (or by some other fixed value) for `Temperature(F)`, `Wind_Chill(F)`, `Humidity(%)`, `Pressure(in)`, `Visibility(mi)`, `Wind_Speed(mph)` and `Precipitation(in)`.\n",
        "- Technique 5 i.e. Replace the columns with one-hot encoded columns for `Weather_Condition`, `Wind_Direction`,  `Sunrise_Sunset`, `Civil_Twilight`, `Nautical_Twilight` and `Astronomical_Twilight`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d9cc807",
      "metadata": {
        "id": "5d9cc807"
      },
      "source": [
        "> Technique 2 i.e. Create a new category for missing values for city column with missing value as unknown category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0b4c92a",
      "metadata": {
        "id": "b0b4c92a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "edd0e060",
      "metadata": {
        "id": "edd0e060"
      },
      "source": [
        "> Technique 3 i.e. Replace them with the most frequent category (or by some other fixed value) for Temperature(F), Wind_Chill(F), Humidity(%), Pressure(in), Visibility(mi), Wind_Speed(mph) and Precipitation(in)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f07b9e35",
      "metadata": {
        "id": "f07b9e35"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a22939",
      "metadata": {
        "id": "61a22939"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "642c070e",
      "metadata": {
        "id": "642c070e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2291d1a",
      "metadata": {
        "id": "d2291d1a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "710a9412",
      "metadata": {
        "id": "710a9412"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33699464",
      "metadata": {
        "id": "33699464"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f6d4a0e5",
      "metadata": {
        "id": "f6d4a0e5"
      },
      "source": [
        "> Technique 5 i.e. Replace the columns with one-hot encoded columns for Weather_Condition, Wind_Direction, Sunrise_Sunset, Civil_Twilight, Nautical_Twilight and Astronomical_Twilight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59b2abc6",
      "metadata": {
        "id": "59b2abc6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93f81166",
      "metadata": {
        "id": "93f81166"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b54f72a4",
      "metadata": {
        "id": "b54f72a4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "672e36a5",
      "metadata": {
        "id": "672e36a5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d7d891ed",
      "metadata": {
        "id": "d7d891ed"
      },
      "source": [
        "- You can either drop the original columns after onehot encoding or you can keep them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "763a8ea5",
      "metadata": {
        "id": "763a8ea5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfa26433",
      "metadata": {
        "id": "dfa26433"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cc397f66",
      "metadata": {
        "id": "cc397f66"
      },
      "source": [
        "- We will be following the same procedures as `accidents_df` for handling missing values in `dask_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce37cfe",
      "metadata": {
        "id": "0ce37cfe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bfbecd1",
      "metadata": {
        "id": "9bfbecd1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f432902c",
      "metadata": {
        "id": "f432902c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11af1596",
      "metadata": {
        "id": "11af1596"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db2503b",
      "metadata": {
        "id": "5db2503b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e084b4",
      "metadata": {
        "id": "d9e084b4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ebf1053",
      "metadata": {
        "id": "9ebf1053"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc92b3e2",
      "metadata": {
        "id": "dc92b3e2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "af9f9e08",
      "metadata": {
        "id": "af9f9e08"
      },
      "source": [
        "**OBSERVATION**: Dask dataframe seems to take less time when performing these operations, right?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8968dbbc",
      "metadata": {
        "id": "8968dbbc"
      },
      "source": [
        "> **EXERCISE**: Check for duplicates in `accidents_df` and remove them if required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da60a334",
      "metadata": {
        "id": "da60a334"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad3d76dc",
      "metadata": {
        "id": "ad3d76dc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bc56c447",
      "metadata": {
        "id": "bc56c447"
      },
      "source": [
        "**OBSERVATION**: No duplicates to remove!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8e95fac",
      "metadata": {
        "id": "b8e95fac"
      },
      "source": [
        "> **EXERCISE**: Repeat the exercises in this section with `accidents_df` and `accidents_dask_df` and track the time taken by each operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "266c8693",
      "metadata": {
        "id": "266c8693"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "653284e2",
      "metadata": {
        "id": "653284e2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc0ad9f4",
      "metadata": {
        "id": "dc0ad9f4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4924754",
      "metadata": {
        "id": "c4924754"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cf6bd415",
      "metadata": {
        "id": "cf6bd415"
      },
      "source": [
        "**OBSERVATION**: Again, Dask dataframe seems to perform faster!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad13db1",
      "metadata": {
        "id": "0ad13db1"
      },
      "source": [
        "> **EXERCISE**: Try out some more arithmetic operations with other numeric columns of `accidents_df` and `accidents_dask_df`. Measure and compare the time taken for each operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68cfd5cd",
      "metadata": {
        "id": "68cfd5cd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c09f868",
      "metadata": {
        "id": "4c09f868"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6da73f56",
      "metadata": {
        "id": "6da73f56"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0525e533",
      "metadata": {
        "id": "0525e533"
      },
      "source": [
        "**OBSERVATION**: Dask dataframe seems to be winning all the races so far!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "599861d9",
      "metadata": {
        "id": "599861d9"
      },
      "source": [
        "> **EXERCISE**: Look up the documentation for the `applymap` method of a data frame. How is it different from `apply` and `map` methods? Demonstrate with examples."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "506f59e0",
      "metadata": {
        "id": "506f59e0"
      },
      "source": [
        "- `apply()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e67d0b4e",
      "metadata": {
        "id": "e67d0b4e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "073156cb",
      "metadata": {
        "id": "073156cb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90506d56",
      "metadata": {
        "id": "90506d56"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc6cb6e2",
      "metadata": {
        "id": "bc6cb6e2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4952988d",
      "metadata": {
        "id": "4952988d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "00f3384f",
      "metadata": {
        "id": "00f3384f"
      },
      "source": [
        "- `map()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64a5846d",
      "metadata": {
        "id": "64a5846d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3ac0e12e",
      "metadata": {
        "id": "3ac0e12e"
      },
      "source": [
        "![](https://i.imgur.com/Az4o01Q.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69ef10a7",
      "metadata": {
        "id": "69ef10a7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18515a2f",
      "metadata": {
        "id": "18515a2f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "25cb3f37",
      "metadata": {
        "id": "25cb3f37"
      },
      "source": [
        "- `applymap()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c1e5ee2",
      "metadata": {
        "id": "3c1e5ee2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3207810",
      "metadata": {
        "id": "e3207810"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e6178088",
      "metadata": {
        "id": "e6178088"
      },
      "source": [
        "**OBSERVATION**: Major difference between `apply()`, `map()` and `applymap()` is-\n",
        "- `apply()` works on both dataframes and pandas series.\n",
        "- `map()` works only on pandas series.\n",
        "- `applymap()` works only on dataframes.\n",
        "\n",
        "For more differences: [https://stackoverflow.com/questions/19798153/difference-between-map-applymap-and-apply-methods-in-pandas]()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e805a4c9",
      "metadata": {
        "id": "e805a4c9"
      },
      "source": [
        "> **EXERCISE**: Repeat the operations performed in this section (type-specific functions) with `accidents_df` and `accidents_dask_df`. Measure and compare the time taken for each operation."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a83c0a9a",
      "metadata": {
        "id": "a83c0a9a"
      },
      "source": [
        "- Numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46ea8e91",
      "metadata": {
        "id": "46ea8e91"
      },
      "source": [
        "`accidents_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc948c19",
      "metadata": {
        "id": "bc948c19"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4b90f91",
      "metadata": {
        "id": "d4b90f91"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56a25130",
      "metadata": {
        "id": "56a25130"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f41dd820",
      "metadata": {
        "id": "f41dd820"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eae8991",
      "metadata": {
        "id": "8eae8991"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "293bd033",
      "metadata": {
        "id": "293bd033"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90770f2d",
      "metadata": {
        "id": "90770f2d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e09252bf",
      "metadata": {
        "id": "e09252bf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30e20071",
      "metadata": {
        "id": "30e20071"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3143cc6",
      "metadata": {
        "id": "c3143cc6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ed90baa5",
      "metadata": {
        "id": "ed90baa5"
      },
      "source": [
        "`dask_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea94162d",
      "metadata": {
        "id": "ea94162d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dbfec6c",
      "metadata": {
        "id": "9dbfec6c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb278729",
      "metadata": {
        "id": "cb278729"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3b89415",
      "metadata": {
        "id": "c3b89415"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15856c28",
      "metadata": {
        "id": "15856c28"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd4d8be",
      "metadata": {
        "id": "afd4d8be"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5eb1a56",
      "metadata": {
        "id": "d5eb1a56"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e9fe580",
      "metadata": {
        "id": "4e9fe580"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7805bc22",
      "metadata": {
        "id": "7805bc22"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bbb9930",
      "metadata": {
        "id": "2bbb9930"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "947634ac",
      "metadata": {
        "id": "947634ac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3fb606b2",
      "metadata": {
        "id": "3fb606b2"
      },
      "source": [
        "- Strings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84fe5653",
      "metadata": {
        "id": "84fe5653"
      },
      "source": [
        "`accidents_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04435af0",
      "metadata": {
        "id": "04435af0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "300002f3",
      "metadata": {
        "id": "300002f3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dc02e9b",
      "metadata": {
        "id": "1dc02e9b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8caad7f4",
      "metadata": {
        "id": "8caad7f4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "661c591c",
      "metadata": {
        "id": "661c591c"
      },
      "source": [
        "`dask_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1372265b",
      "metadata": {
        "id": "1372265b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df8e9a9e",
      "metadata": {
        "id": "df8e9a9e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ab29b56",
      "metadata": {
        "id": "6ab29b56"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7d01938",
      "metadata": {
        "id": "c7d01938"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "63af9404",
      "metadata": {
        "id": "63af9404"
      },
      "source": [
        "- Dates"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9c84f05",
      "metadata": {
        "id": "c9c84f05"
      },
      "source": [
        "`accidents_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7429c7ed",
      "metadata": {
        "id": "7429c7ed"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdbcbaf7",
      "metadata": {
        "id": "bdbcbaf7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a41953",
      "metadata": {
        "id": "c0a41953"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "147717c4",
      "metadata": {
        "id": "147717c4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e07c2943",
      "metadata": {
        "id": "e07c2943"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb82269f",
      "metadata": {
        "id": "bb82269f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "beeab0a1",
      "metadata": {
        "id": "beeab0a1"
      },
      "source": [
        "`dask_df`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "981519c7",
      "metadata": {
        "id": "981519c7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fab0fef6",
      "metadata": {
        "id": "fab0fef6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1053bc34",
      "metadata": {
        "id": "1053bc34"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3226c255",
      "metadata": {
        "id": "3226c255"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afb6ef80",
      "metadata": {
        "id": "afb6ef80"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f721061b",
      "metadata": {
        "id": "f721061b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b10df9e0",
      "metadata": {
        "id": "b10df9e0"
      },
      "source": [
        "**OBSERVATION**: Dask dataframe is proving itself over and over again with it's fastness."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9723c144",
      "metadata": {
        "id": "9723c144"
      },
      "source": [
        "Learn more about `map` and `apply` here: https://towardsdatascience.com/introduction-to-pandas-apply-applymap-and-map-5d3e044e93ff"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4484432",
      "metadata": {
        "id": "f4484432"
      },
      "source": [
        "> **EXERCISE**: Remove the column `D` from `df3`. How does it affect the result of vertical concatenation? Try passing the argument `join=\"inner\"` to `pd.concat`. Do you observe any change?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6c68605",
      "metadata": {
        "id": "b6c68605"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5dd135c2",
      "metadata": {
        "id": "5dd135c2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2ecbdf5a",
      "metadata": {
        "id": "2ecbdf5a"
      },
      "source": [
        "**OBSERVATION**: The entire `D` column (`D` column in `df1` and `df2`) is dropped from the concatenated dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d3cc321",
      "metadata": {
        "id": "1d3cc321"
      },
      "source": [
        "> **EXERCISE**: Create two dataframes that don't have any common columns and concatenate them vertically. What do you observe? Try providing the arguments `join=\"outer\"` and `join=\"inner\"`. How do they affect the results?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "625ce3d8",
      "metadata": {
        "id": "625ce3d8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30102d31",
      "metadata": {
        "id": "30102d31"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "01ce0ceb",
      "metadata": {
        "id": "01ce0ceb"
      },
      "source": [
        "**OBSERVATION**: Due to difference in index values (indices are not aligned),  we get `NaN`s when we concatenate the dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd82a1ea",
      "metadata": {
        "id": "bd82a1ea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2dfab2a3",
      "metadata": {
        "id": "2dfab2a3"
      },
      "source": [
        "**OBSERVATION**: `join=\"inner\"` returns a dataframe with columns that are common in both the dataframes. As there are no common columns in both the dataframes, it is returning an empty dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2706446",
      "metadata": {
        "id": "f2706446"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b1792cf5",
      "metadata": {
        "id": "b1792cf5"
      },
      "source": [
        "**OBSERVTAION**: `join=\"outer\"` is the same dataframe as without it. In fact, `join=\"outer\"` is a default setting when performing concatenation.  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6309231c",
      "metadata": {
        "id": "6309231c"
      },
      "source": [
        "> **EXERCISE**: Demonstrate the four types of join listed above using the following dataframes. Use the `key` column for merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4104ec3d",
      "metadata": {
        "id": "4104ec3d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09a4f23e",
      "metadata": {
        "id": "09a4f23e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77162e21",
      "metadata": {
        "id": "77162e21"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a45c43c",
      "metadata": {
        "id": "6a45c43c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d85cb0a2",
      "metadata": {
        "id": "d85cb0a2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9b16521",
      "metadata": {
        "id": "b9b16521"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86afb3e9",
      "metadata": {
        "id": "86afb3e9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "152ffbea",
      "metadata": {
        "id": "152ffbea"
      },
      "source": [
        "> **EXERCISE**: Show an example of merging two dataframes on two columns.\n",
        ">\n",
        "> *Hint*: Read the docs: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95194414",
      "metadata": {
        "id": "95194414"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd973f12",
      "metadata": {
        "id": "dd973f12"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "22a7c1b2",
      "metadata": {
        "id": "22a7c1b2"
      },
      "source": [
        "> **EXERCISE**: Look up the documentation for the `pd.join` function. How is it different from `pd.merge`? Demonstrate with examples. Hint: A join is always performed on the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3333c37",
      "metadata": {
        "id": "c3333c37"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1ab85de",
      "metadata": {
        "id": "c1ab85de"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ce404e2",
      "metadata": {
        "id": "1ce404e2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab244517",
      "metadata": {
        "id": "ab244517"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "54d7af8d",
      "metadata": {
        "id": "54d7af8d"
      },
      "source": [
        "![](https://i.imgur.com/4FzBs5L.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9844a99",
      "metadata": {
        "id": "e9844a99"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07066608",
      "metadata": {
        "id": "07066608"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ff5e0cc7",
      "metadata": {
        "id": "ff5e0cc7"
      },
      "source": [
        "**OBSERVATION**: `merge()` doesn't have this restriction so it works perfectly fine even without setting the index!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "88cb70a5",
        "0e5691e2",
        "41ebb440",
        "be94ef82",
        "05140419",
        "b02343d0",
        "c972a987",
        "b3a39d11",
        "12dcdf97"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}