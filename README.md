# Data_Science_bootcamp

Project 1 - Web Scraping with Python
In this project, you will apply your knowledge of Python and its ecosystem of libraries to scrape information from a website and create a dataset of CSV file(s). Here are the steps you'll follow:

- Pick a website and describe your objective

Browse through different sites and pick on to scrape. Check the "Project Ideas" section for inspiration.
Identify the information you'd like to scrape from the site. Decide the format of the output CSV file.
Summarize your project idea in a paragraph using a Markdown cell and outline your strategy.

- Use the requests library to download web pages

Inspect the website's HTML source and identify the right URLs to download.
Download and save web pages locally using the requests library.
Create a function to automate downloading for different topics/search queries.

- Use Beautiful Soup to parse and extract information

Parse and explore the structure of downloaded web pages using Beautiful soup.
Use the right properties and methods to extract the required information.
Create functions to extract from the page into lists and dictionaries.
(Optional) Use a REST API to acquire additional information if required.

- Create CSV file(s) with the extracted information

Create functions for the end-to-end process of downloading, parsing, and saving CSVs.
Execute the function with different inputs to create a dataset of CSV files.
Attach the CSV files with your notebook using jovian.commit.

- Document and share your work

Add proper headings and documentation in your Jupyter notebook.
Publish your Jupyter notebook to Jovian and make a submission.
(Optional) Write a blog post about your project and share it online.
