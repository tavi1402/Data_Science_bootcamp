{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tavi1402/Data_Science_bootcamp/blob/main/3_1_python_web_scraping_and_rest_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9a91bde",
      "metadata": {
        "id": "a9a91bde"
      },
      "source": [
        "# Introduction to Web Scraping and REST APIs\n",
        "\n",
        "![](https://i.imgur.com/6zM7JBq.png)\n",
        "\n",
        "\n",
        "Web scraping is the process of extracting and parsing data from websites in an automated fashion using a computer program. It's a useful technique for creating datasets for research and learning. While web scraping often involves parsing and processing [HTML documents](https://developer.mozilla.org/en-US/docs/Web/HTML), some platforms also offer [REST APIs](https://www.smashingmagazine.com/2018/01/understanding-using-rest-api/) to retrieve information in a machine-readable format like [JSON](https://www.digitalocean.com/community/tutorials/an-introduction-to-json). In this tutorial, we'll use web scraping and REST APIs to create a real-world dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d358e104",
      "metadata": {
        "id": "d358e104"
      },
      "source": [
        "This tutorial covers the following topics:\n",
        "\n",
        "* Downloading web pages using the requests library\n",
        "* Inspecting the HTML source code of a web page\n",
        "* Parsing parts of a website using Beautiful Soup\n",
        "* Writing parsed information into CSV files\n",
        "* Using a REST API to retrieve data as JSON\n",
        "* Combining data from multiple sources\n",
        "* Using links on a page to crawl a website\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29df835a",
      "metadata": {
        "id": "29df835a"
      },
      "source": [
        "### How to Run the Code\n",
        "\n",
        "The best way to learn the material is to execute the code and experiment with it yourself. This tutorial is an executable [Jupyter notebook](https://jupyter.org). You can _run_ this tutorial and experiment with the code examples in a couple of ways: *using free online resources* (recommended) or *on your computer*.\n",
        "\n",
        "#### Option 1: Running using free online resources (1-click, recommended)\n",
        "\n",
        "The easiest way to start executing the code is to click the **Run** button at the top of this page and select **Run on Binder**. You can also select \"Run on Colab\" or \"Run on Kaggle\", but you'll need to create an account on [Google Colab](https://colab.research.google.com) or [Kaggle](https://kaggle.com) to use these platforms.\n",
        "\n",
        "\n",
        "#### Option 2: Running on your computer locally\n",
        "\n",
        "To run the code on your computer locally, you'll need to set up [Python](https://www.python.org), download the notebook and install the required libraries. We recommend using the [Conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/) distribution of Python. Click the **Run** button at the top of this page, select the **Run Locally** option, and follow the instructions.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b60c344",
      "metadata": {
        "id": "9b60c344"
      },
      "source": [
        "## Problem\n",
        "\n",
        "Over the course of this tutorial, we'll solve the following problem to learn the tools and techniques used for web scraping:\n",
        "\n",
        "\n",
        "> **QUESTION**: Write a Python function that creates a CSV file (comma-separated values) containing details about the 25 top GitHub repositories for any given topic. You can view the top repositories for the topic `machine-learning` on this page: [https://github.com/topics/machine-learning](https://github.com/topics/machine-learning). The output CSV should contain these details: repository name, owner's username, no. of stars, repository URL.\n",
        "\n",
        "\n",
        " <a href=\"https://github.com/topics/machine-learning\"><img src=\"https://i.imgur.com/5V1HGLs.png\" width=\"480\" style=\"box-shadow:rgba(52, 64, 77, 0.2) 0px 1px 5px 0px;border-radius:4px;\"></a>\n",
        "\n",
        "\n",
        "How would you go about solving this problem in Python? Explore the web page and take a couple of minutes to come up with an approach before proceeding further. How many lines of code do you think the solution will require?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2c668d3",
      "metadata": {
        "id": "f2c668d3"
      },
      "source": [
        "## Downloading a web page using `requests`\n",
        "\n",
        "When you access a URL like https://github.com/topics/machine-learning using a web browser, it downloads the contents of the web page the URL points to and displays the output on the screen. Before we can extract information from a web page, we need to download the page using Python.\n",
        "\n",
        "We'll use a library called [`requests`](https://docs.python-requests.org/en/master/) to download web pages from the internet. Let's begin by installing and importing the library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "921da3e7",
      "metadata": {
        "id": "921da3e7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09a3003a",
      "metadata": {
        "id": "09a3003a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e1abcc88",
      "metadata": {
        "id": "e1abcc88"
      },
      "source": [
        "We can download a web page using the `requests.get` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd23a9b",
      "metadata": {
        "id": "9fd23a9b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef7aa941",
      "metadata": {
        "id": "ef7aa941"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba73b45b",
      "metadata": {
        "id": "ba73b45b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "af229f30",
      "metadata": {
        "id": "af229f30"
      },
      "source": [
        "`requests.get` returns a response object with the page contents and some information indicating whether the request was successful, using a status code. Learn more about HTTP status codes here: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status.\n",
        "\n",
        " If the request was successful, `response.status_code` is set to a value between 200 and 299."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07df685f",
      "metadata": {
        "id": "07df685f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c7983145",
      "metadata": {
        "id": "c7983145"
      },
      "source": [
        "The contents of the web page can be accessed using the `.text` property of the `response`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2058759",
      "metadata": {
        "id": "e2058759"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae6f4ef5",
      "metadata": {
        "id": "ae6f4ef5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b3ac90c4",
      "metadata": {
        "id": "b3ac90c4"
      },
      "source": [
        "The page contains over 60,000 characters! Let's view the first 1000 characters of the web page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3594cf16",
      "metadata": {
        "id": "3594cf16"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dacf443d",
      "metadata": {
        "id": "dacf443d"
      },
      "source": [
        "What you see above is the *source code* of the web page. It written in a language called [HTML](https://developer.mozilla.org/en-US/docs/Web/HTML). It defines the content and structure of the web page.\n",
        "\n",
        "Let's save the contents to a file with the `.html` extension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50aed0be",
      "metadata": {
        "id": "50aed0be"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "91872538",
      "metadata": {
        "id": "91872538"
      },
      "source": [
        "You can now view the file using the \"File > Open\" menu option within Jupyter and clicking on *machine-learning.html* in the list of files displayed. Here's what you'll see when you open the file:\n",
        "\n",
        "<img src=\"https://i.imgur.com/8gEbT1P.png\" width=\"480\" style=\"box-shadow:rgba(52, 64, 77, 0.2) 0px 1px 5px 0px;border-radius:4px;\">\n",
        "\n",
        "While this looks similar to the original web page, note that it's simply a copy. You will notice that none of the links or buttons work. To view or edit the source code of the file, click \"File > Open\" within Jupyter, then select the file *machine-learning.html* from the list and click the \"Edit\" button.\n",
        "\n",
        "<img src=\"https://i.imgur.com/JG7Q8CK.png\" width=\"480\" style=\"box-shadow:rgba(52, 64, 77, 0.2) 0px 1px 5px 0px;border-radius:4px;\">\n",
        "\n",
        "As you might expect, the source code looks something like this:\n",
        "\n",
        "<img src=\"https://i.imgur.com/6ynXNdz.png\" width=\"480\" style=\"box-shadow:rgba(52, 64, 77, 0.2) 0px 1px 5px 0px;border-radius:4px;\">\n",
        "\n",
        "Try scrolling through the source code. Can you make sense of it? Can you see how the information on the page is organized within the file? We'll learn more about it in the next section."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c01efd5",
      "metadata": {
        "id": "0c01efd5"
      },
      "source": [
        "> **EXERCISE**: Download the web page for a different topic, e.g., https://github.com/topics/data-analysis using `requests` and save it to a file, e.g., `data-analysis.html`. View the page and compare it with the previously downloaded page? How are the two different? Can you spot the differences in the source code?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bde9e77",
      "metadata": {
        "id": "8bde9e77"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8291ce47",
      "metadata": {
        "id": "8291ce47"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9d5c4d9",
      "metadata": {
        "id": "b9d5c4d9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "cba03c4f",
      "metadata": {
        "id": "cba03c4f"
      },
      "source": [
        "Let's save our work using `jovian` before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2f3b73",
      "metadata": {
        "id": "bd2f3b73"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19fa17b9",
      "metadata": {
        "id": "19fa17b9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "525d7b2e",
      "metadata": {
        "id": "525d7b2e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0818c507",
      "metadata": {
        "id": "0818c507"
      },
      "source": [
        "## Inspecting the HTML source code of a web page\n",
        "\n",
        "![](https://i.imgur.com/mvBpQIP.png)\n",
        "\n",
        "As mentioned earlier, web pages are written in a language called HTML (Hyper Text Markup Language). HTML is a fairly simple language comprised of *tags*  (also called *nodes* or *elements*) e.g. `<a href=\"https://jovian.ai\" target=\"_blank\">Go to Jovian</a>`. An HTML tag has three parts:\n",
        "\n",
        "1. **Name**: (`html`, `head`, `body`, `div`, etc.) Indicates what the tag represents and how a browser should interpret the information inside it.\n",
        "2. **Attributes**: (`href`, `target`, `class`, `id`, etc.) Properties of tag used by the browser to customize how a tag is displayed and decide what happens on user interactions.\n",
        "3. **Children**: A tag can contain some text or other tags or both between the opening and closing segments, e.g., `<div>Some content</div>`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6df7e1d",
      "metadata": {
        "id": "c6df7e1d"
      },
      "source": [
        "### Inside an HTML Document\n",
        "\n",
        "Here's a simple HTML document that uses many commonly used tags:\n",
        "\n",
        "```html\n",
        "<html>\n",
        "  <head>\n",
        "    <title>All About Python</title>\n",
        "  </head>\n",
        "  <body>\n",
        "    <div style=\"width: 640px; margin: 40px auto\">\n",
        "      <h1 style=\"text-align:center;\">Python - A Programming Language</h1>\n",
        "      <img src=\"https://www.python.org/static/community_logos/python-logo-master-v3-TM.png\" alt=\"python-logo\" style=\"width:240px;margin:0 auto;display:block;\">\n",
        "      <div>\n",
        "        <h2>About Python</h2>\n",
        "        <p>\n",
        "          Python is an <span style=\"font-style: italic\">interpreted, high-level and general-purpose</span> programming language. Python's design philosophy emphasizes code readability with its notable use of significant indentation. Its language constructs and object-oriented approach aim to help programmers write clear, logical code for small and large-scale projects. Visit the <a href=\"https://docs.python.org/3/\">official documentation</a> to learn more.\n",
        "        </p>\n",
        "      </div>\n",
        "      <div>\n",
        "        <h2>Some Python Libraries</h2>\n",
        "        <ul id=\"libraries\">\n",
        "          <li>Numpy</li>\n",
        "          <li>Pandas</li>\n",
        "          <li>PyTorch</li>\n",
        "          <li>Scikit Learn</li>\n",
        "        </ul>\n",
        "      </div>\n",
        "      <div>\n",
        "        <h2>Recent Python Versions</h2>\n",
        "        <table id=\"versions-table\">\n",
        "          <tr>\n",
        "            <th class=\"bordered-table\">Version</th>\n",
        "            <th class=\"bordered-table\">Released on</th>\n",
        "          </tr>\n",
        "          <tr>\n",
        "            <td class=\"bordered-table\">Python 3.8</td>\n",
        "            <td class=\"bordered-table\">October 2019</td>\n",
        "          </tr>\n",
        "          <tr>\n",
        "            <td class=\"bordered-table\">Python 3.7</td>\n",
        "            <td class=\"bordered-table\">June 2018</td>\n",
        "          </tr>\n",
        "        </table>\n",
        "          <style>\n",
        "              .bordered-table {\n",
        "                  border: 1px solid black; padding: 8px;\n",
        "              }\n",
        "          </style>\n",
        "      </div>\n",
        "    </div>\n",
        "  </body>\n",
        "</html>\n",
        "\n",
        "```\n",
        "\n",
        "> **EXERCISE**: Copy the above HTML code and paste it into a new file called `webpage.html`. To create a new file,  select \"File > Open\" from the menu bar, then select \"New > Text\" file. View the saved file. Can you see how the different tags are displayed in different ways by the browser?\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/lcSHz5V.png\" width=\"480\" style=\"box-shadow:rgba(52, 64, 77, 0.2) 0px 1px 5px 0px;border-radius:4px;\">\n",
        "\n",
        "> **EXERCISE**: Make some changes to the code inside `webpage.html`. Save the file and view it again. Do you see your changes reflected? Play with the structure of the file. Try to break things and fix them!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ea9fa4",
      "metadata": {
        "id": "95ea9fa4"
      },
      "source": [
        "### Common Tags and Attributes\n",
        "\n",
        "Following are some of the most commonly used HTML tags:\n",
        "\n",
        "* `html`\n",
        "* `head`\n",
        "* `title`\n",
        "* `body`\n",
        "* `div`\n",
        "* `span`\n",
        "* `h1` to `h6`\n",
        "* `p`\n",
        "* `img`\n",
        "* `ul`, `ol` and `li`\n",
        "* `table`, `tr`, `th` and `td`\n",
        "* `style`\n",
        "* ...\n",
        "\n",
        "Each tag supports several attributes. Following are some common attributes used to modify the behavior of tags:\n",
        "\n",
        "* `id`\n",
        "* `style`\n",
        "* `class`\n",
        "* `href` (used with `<a>`)\n",
        "* `src` (used with `<img>`)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> **EXERCISE**: Complete this tutorial on HTML: https://www.htmldog.com/guides/html/ . Once done, try describing what the above tags and attributes are used for. Try creating a new HTML page using the tags you find most interesting.\n",
        ">\n",
        "> To learn how to style HTML tags, check out this tutorial on CSS: https://www.htmldog.com/guides/css/\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a56d65f4",
      "metadata": {
        "id": "a56d65f4"
      },
      "source": [
        "### Inspecting HTML in the Browser\n",
        "\n",
        "You can view the source code of any webpage right within your browser by right-clicking anywhere on a page and selecting the \"Inspect\" option. It opens the \"Developer Tools\" pane, where you can see the source code as a tree. You can expand and collapse various nodes and find the source code for a specific portion of the page.\n",
        "\n",
        "Here's what it looks like on the Chrome browser:\n",
        "\n",
        "\n",
        "<img src=\"https://i.imgur.com/jCA1T6Z.png\" width=\"640\" style=\"box-shadow:rgba(52, 64, 77, 0.2) 0px 1px 5px 0px;border-radius:4px;\">\n",
        "\n",
        "\n",
        "> **EXERCISE**: Explore the source code of the web page https://github.com/topics/machine-learning . Try to find the portions in the source code corresponding to the repository name, owner's username, and the number of stars for each repository listed on the page."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72114e4",
      "metadata": {
        "id": "e72114e4"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45d02130",
      "metadata": {
        "id": "45d02130"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c548beed",
      "metadata": {
        "id": "c548beed"
      },
      "source": [
        "## Extracting information from HTML using Beautiful Soup\n",
        "\n",
        "To extract information from the HTML source code of a webpage programmatically, we can use the [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) library. Let's install the library and import the `BeautifulSoup` class from the `bs4` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "faa7255d",
      "metadata": {
        "id": "faa7255d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccfd7922",
      "metadata": {
        "id": "ccfd7922"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8de45f19",
      "metadata": {
        "id": "8de45f19"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a49d9efd",
      "metadata": {
        "id": "a49d9efd"
      },
      "source": [
        "Next, let's read the contents of the file `machine-learning.html` and create a `BeautifulSoup` object to parse the content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef8139d8",
      "metadata": {
        "id": "ef8139d8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e9ebc7",
      "metadata": {
        "id": "38e9ebc7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d04a691f",
      "metadata": {
        "id": "d04a691f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b51f29c",
      "metadata": {
        "id": "5b51f29c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "34a4626d",
      "metadata": {
        "id": "34a4626d"
      },
      "source": [
        "The `doc` object contains several properties and methods for extracting information from the HTML document. Let's look at a few examples below.\n",
        "\n",
        "**NOTE**: You don't need to remember all (or any) of the properties/methods. You can look up [the documentation of BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) or [search online](https://www.google.co.in/search?q=beautifulsoup+how+to+get+href+of+link) to find what you need when you need it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc8ed84a",
      "metadata": {
        "id": "dc8ed84a"
      },
      "source": [
        "### Accessing a tag\n",
        "\n",
        "> **QUESTION**: Find the title of the page represented by `doc`.\n",
        "\n",
        "The title of the page is contained within the `<title>` tag. We can access the title tag using `doc.title`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44945695",
      "metadata": {
        "id": "44945695"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b0c702",
      "metadata": {
        "id": "e5b0c702"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fcfad84",
      "metadata": {
        "id": "7fcfad84"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "51313796",
      "metadata": {
        "id": "51313796"
      },
      "source": [
        "We can access a tag's name using the `.name` property."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62e7e9be",
      "metadata": {
        "id": "62e7e9be"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2a16d31c",
      "metadata": {
        "id": "2a16d31c"
      },
      "source": [
        "The text within a tag can be accessed using `.text`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55fe0e2e",
      "metadata": {
        "id": "55fe0e2e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "6a1c66c2",
      "metadata": {
        "id": "6a1c66c2"
      },
      "source": [
        "> **EXERCISE**: Explore the `html`, `body`, and `head` tags of `doc`. Do you see what you expect to see?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db19f710",
      "metadata": {
        "id": "db19f710"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4630d302",
      "metadata": {
        "id": "4630d302"
      },
      "source": [
        "If a tag occurs more than once in a document e.g. `<a>` (which represents links), then `doc.a` finds the first `<a>` tag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f50ee6",
      "metadata": {
        "id": "79f50ee6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6919dd0b",
      "metadata": {
        "id": "6919dd0b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8290acbe",
      "metadata": {
        "id": "8290acbe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "073ce75f",
      "metadata": {
        "id": "073ce75f"
      },
      "source": [
        "> **EXERCISE**: Find the first occurrence of each of these tags in `doc`: `div`, `img`, `span`, `p`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e22807d",
      "metadata": {
        "id": "0e22807d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9200cbfc",
      "metadata": {
        "id": "9200cbfc"
      },
      "source": [
        "### Finding all tags of the same type\n",
        "\n",
        "To find all the occurrences of a tag, use the `find_all` method.\n",
        "\n",
        "> **QUESTION**: Find all the link tags on the page. How many links does the page contain?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10f078fc",
      "metadata": {
        "id": "10f078fc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a17e361d",
      "metadata": {
        "id": "a17e361d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6abcae03",
      "metadata": {
        "id": "6abcae03"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "28d92f0f",
      "metadata": {
        "id": "28d92f0f"
      },
      "source": [
        "> **EXERCISE**: Get a list of all the `img` tags on the page. How many images does the page contain?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7776fd4",
      "metadata": {
        "id": "b7776fd4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ddaaa17a",
      "metadata": {
        "id": "ddaaa17a"
      },
      "source": [
        "### Accessing attributes\n",
        "\n",
        "The attributes of a tag can be accessed using the indexing notation, e.g., `first_link['href']`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbeb2da2",
      "metadata": {
        "id": "fbeb2da2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e794605b",
      "metadata": {
        "id": "e794605b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aa9d7b2",
      "metadata": {
        "id": "8aa9d7b2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b83b7f6c",
      "metadata": {
        "id": "b83b7f6c"
      },
      "source": [
        "Note that the `class` attribute is automatically split into a list of classes (this isn't done for any other attribute). This is because it's common practice to check for a specific class within a tag."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a938f81",
      "metadata": {
        "id": "0a938f81"
      },
      "source": [
        "You can use the `.attrs` property to view all the attributes as a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14b4fde1",
      "metadata": {
        "id": "14b4fde1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3ded8044",
      "metadata": {
        "id": "3ded8044"
      },
      "source": [
        "> **EXERCISE**: Find the 5th image tag on the page (counting from 0). Which attributes does the tag contain? Find the values of the `src` and `alt` attributes of the tag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72d11f80",
      "metadata": {
        "id": "72d11f80"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8617435f",
      "metadata": {
        "id": "8617435f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e146b53a",
      "metadata": {
        "id": "e146b53a"
      },
      "source": [
        "### Searching by Attribute Value\n",
        "\n",
        "> **QUESTION**: Find the `img` tag(s) on the page with the `alt` attribute set to `transformers`.\n",
        "\n",
        "We can provide a dictionary of attributes as the second argument to `find_all`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbdd55cd",
      "metadata": {
        "id": "fbdd55cd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e13ebdd1",
      "metadata": {
        "id": "e13ebdd1"
      },
      "source": [
        "If we're just interested in the first element, we can use the `find` method. Keep in mind that `find` returns `None` if no matching tag is found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f1c8bf9",
      "metadata": {
        "id": "8f1c8bf9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "21e6ecf1",
      "metadata": {
        "id": "21e6ecf1"
      },
      "source": [
        "> **EXERCISE**: Find the `src` attribute of the first `img` tag with the `alt` attribute set to `julia`. Visit the link and check what the image represents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a930c877",
      "metadata": {
        "id": "a930c877"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "53cbde04",
      "metadata": {
        "id": "53cbde04"
      },
      "source": [
        "### Searching by Class\n",
        "\n",
        "The `class` attribute is one of the most frequently used attributes on HTML tags (used for layout and styling). We can search for tags containing a class using the `class_` argument in `find_all` (note that `class` is a reserved keyword in Python, hence the underscore in the argument name).\n",
        "\n",
        "> **QUESTION**: Find all the tags containing the class `HeaderMenu-link`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "789777f8",
      "metadata": {
        "id": "789777f8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75e51fb1",
      "metadata": {
        "id": "75e51fb1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bf79ec21",
      "metadata": {
        "id": "bf79ec21"
      },
      "source": [
        "We can also for a specific type of tag e.g. `<a>` matching the given class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16b6a16a",
      "metadata": {
        "id": "16b6a16a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ea7c06",
      "metadata": {
        "id": "c7ea7c06"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2a5ea744",
      "metadata": {
        "id": "2a5ea744"
      },
      "source": [
        "### Parsing Information from Tags\n",
        "\n",
        "Once we have a list of tags matching some criteria, it's easy to extract information and convert it to a more convenient format.\n",
        "\n",
        "> **QUESTION**: Find the link text and URL of all the links withing the page header on https://github.com/topics/machine-learning .\n",
        "\n",
        "We'll create a list of dictionaries containing the required information. We'll add the base URL https://github.com as a prefix because the `href` attribute only contains the relative path e.g. `/explore`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26f8deb5",
      "metadata": {
        "id": "26f8deb5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3075d4f4",
      "metadata": {
        "id": "3075d4f4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ae8d1400",
      "metadata": {
        "id": "ae8d1400"
      },
      "source": [
        "We have successfully extracted the required information about links in the page header. This is precisely what web scraping is: downloading a webpage, parsing the HTML, and extracting useful information."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0eff6b1",
      "metadata": {
        "id": "f0eff6b1"
      },
      "source": [
        "> **EXERCISE**: Find the list of all the images matching the class `d-block width-full`. Each list element should be a dictionary containing two keys, `\"username\"` and `\"url\"`. You can obtain the username using the `alt` attribute of a tag and the URL using the `src` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87b19ea0",
      "metadata": {
        "id": "87b19ea0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebd72cee",
      "metadata": {
        "id": "ebd72cee"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3b7667da",
      "metadata": {
        "id": "3b7667da"
      },
      "source": [
        "### Elements inside a tag\n",
        "\n",
        "> **QUESTION**: Find the `li` tags that are direct children of `ul` tag with the class `top-list` in the sample HTML document below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ec77447",
      "metadata": {
        "id": "9ec77447"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b84eb24c",
      "metadata": {
        "id": "b84eb24c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90f93145",
      "metadata": {
        "id": "90f93145"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fab353f9",
      "metadata": {
        "id": "fab353f9"
      },
      "source": [
        "We can use the `find_all` method on the tag, and set `recursive=False` to find just the direct children."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d10437",
      "metadata": {
        "id": "92d10437"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e1230d0",
      "metadata": {
        "id": "4e1230d0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dddbbce9",
      "metadata": {
        "id": "dddbbce9"
      },
      "source": [
        "Without `recursive=False`, the inner list items are also included in the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33d0befe",
      "metadata": {
        "id": "33d0befe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5b8feb36",
      "metadata": {
        "id": "5b8feb36"
      },
      "source": [
        "Keep in mind that you don't need to remember all (or any) of the methods or properties offered by Beautiful Soup documents and tags. You should be able to figure out what you need to do, when you need to do it. Here's how:\n",
        "\n",
        "* Look up the documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
        "* Google what you're trying to do: https://www.google.co.in/search?q=beautiful+soup+get+href\n",
        "* Ask a question on StackOverflow: https://stackoverflow.com/questions/tagged/beautifulsoup\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "deb2255d",
      "metadata": {
        "id": "deb2255d"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b37da2dd",
      "metadata": {
        "id": "b37da2dd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b5d9c6bc",
      "metadata": {
        "id": "b5d9c6bc"
      },
      "source": [
        "### Top Repositories for a Topic\n",
        "\n",
        "Let's return to our original problem statement of finding the top repositories for a given topic. Before we parse a page and find the top repositories, let's define a helper function to get the web page for any topic.\n",
        "\n",
        "> **QUESTION**: Define a function `get_topic_page` that downloads the GitHub web page for a given topic and returns a beautiful soup document representing the page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92fe1427",
      "metadata": {
        "id": "92fe1427"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06a17607",
      "metadata": {
        "id": "06a17607"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a3fce57",
      "metadata": {
        "id": "9a3fce57"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0836db78",
      "metadata": {
        "id": "0836db78"
      },
      "source": [
        "Getting the topic page for another topic is now as simple as invoking the function with a different argument."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c17c7472",
      "metadata": {
        "id": "c17c7472"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45ae4316",
      "metadata": {
        "id": "45ae4316"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "05b80f9f",
      "metadata": {
        "id": "05b80f9f"
      },
      "source": [
        "> **QUESTION**: Develop an approach to find the repository name, owner's username, no. of stars, and repository link for the repositories listed on a topic page.\n",
        "\n",
        "<img src=\"https://i.imgur.com/szL76cU.png\" width=\"640\" style=\"box-shadow:rgba(52, 64, 77, 0.2) 0px 1px 5px 0px;border-radius:4px;\">\n",
        "\n",
        "Upon inspecting the box containing the information for a repository, you will find an `article` tag for each repository, with `class` attribute set to  `border rounded color-shadow-small color-bg-secondary my-4`.\n",
        "\n",
        "Let's find all the `article` tags matching this class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7e76764",
      "metadata": {
        "id": "b7e76764"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b529bc5",
      "metadata": {
        "id": "0b529bc5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "83321b67",
      "metadata": {
        "id": "83321b67"
      },
      "source": [
        "There are 30 repositories listed on the page, and our query resulted in 30 article tags. It looks like we've found the enclosing tag for each repository.\n",
        "\n",
        "We need to extract the following information from each tag:\n",
        "\n",
        "1. Repository name\n",
        "2. Owner's username\n",
        "3. Number of stars\n",
        "4. Repository link\n",
        "\n",
        "Look at the source of any of the article tags. You will notice that the repository name, owner's username, and the repository link are all part of an `h1` tag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d1fe993",
      "metadata": {
        "id": "3d1fe993"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12f52464",
      "metadata": {
        "id": "12f52464"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ee8d7d6c",
      "metadata": {
        "id": "ee8d7d6c"
      },
      "source": [
        "Let's retrieve the first `h1` inside an article."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "793deae8",
      "metadata": {
        "id": "793deae8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5649fbb8",
      "metadata": {
        "id": "5649fbb8"
      },
      "source": [
        "The `h1` has `a` tags inside it, one containing the owner's username and the second containing the repository title. The `href` of the second tag also includes the relative path of the repository. Let's extract this information from the `a` tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e685008d",
      "metadata": {
        "id": "e685008d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d573cdcb",
      "metadata": {
        "id": "d573cdcb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c85824ff",
      "metadata": {
        "id": "c85824ff"
      },
      "source": [
        "Looks like the username contains some leading and trailing whitespace. We can get rid of it using `strip`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5cab250",
      "metadata": {
        "id": "c5cab250"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7aabf7c4",
      "metadata": {
        "id": "7aabf7c4"
      },
      "source": [
        "We can get the repository name and repository path in the same fashion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f79c370",
      "metadata": {
        "id": "2f79c370"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "398d97a9",
      "metadata": {
        "id": "398d97a9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d981d566",
      "metadata": {
        "id": "d981d566"
      },
      "source": [
        "To get the full URL to the repository, we can append the base URL `https://github.com` at the beginning of the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27053f7c",
      "metadata": {
        "id": "27053f7c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2a929a54",
      "metadata": {
        "id": "2a929a54"
      },
      "source": [
        "\n",
        "Next, to get the number of starts, we notice that it is contained within an `span` tag which has the count `Counter js-social-count`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "476106a0",
      "metadata": {
        "id": "476106a0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94087a52",
      "metadata": {
        "id": "94087a52"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d36d2f5",
      "metadata": {
        "id": "9d36d2f5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "344583fa",
      "metadata": {
        "id": "344583fa"
      },
      "source": [
        "Let's extract the star count from the `a` tag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e23d81a",
      "metadata": {
        "id": "1e23d81a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "916a9120",
      "metadata": {
        "id": "916a9120"
      },
      "source": [
        "The `k` at the end indicates `1000`. Let's write a helper function which can convert strings like `40.3k` into the number `40,300`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dd35c6f",
      "metadata": {
        "id": "7dd35c6f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7874b56",
      "metadata": {
        "id": "e7874b56"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a041636",
      "metadata": {
        "id": "0a041636"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "970157ad",
      "metadata": {
        "id": "970157ad"
      },
      "source": [
        "We can now determine the star count as a number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d672904e",
      "metadata": {
        "id": "d672904e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fd6b0be",
      "metadata": {
        "id": "4fd6b0be"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2633b0cf",
      "metadata": {
        "id": "2633b0cf"
      },
      "source": [
        "Perfect, we've extracted all the information we were interested in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2f68441",
      "metadata": {
        "id": "b2f68441"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "39107171",
      "metadata": {
        "id": "39107171"
      },
      "source": [
        "Let's extract the logic for parsing the required information from an article tag into a function.\n",
        "\n",
        "> **QUESTION**: Write a function `parse_repostory` that returns a dictionary containing the repository name, owner's username, number of stars, and repository URL by parsing a given `article` tag representing a repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76e90dd5",
      "metadata": {
        "id": "76e90dd5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7b10d6c1",
      "metadata": {
        "id": "7b10d6c1"
      },
      "source": [
        "We can now use the function to parse any `article` tag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc20c396",
      "metadata": {
        "id": "cc20c396"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7c2a55e",
      "metadata": {
        "id": "b7c2a55e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "834b84c7",
      "metadata": {
        "id": "834b84c7"
      },
      "source": [
        "We can use a list comprehension to parse all the `article` tags in one go."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6779d6bd",
      "metadata": {
        "id": "6779d6bd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4531eb1f",
      "metadata": {
        "id": "4531eb1f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92fbbf79",
      "metadata": {
        "id": "92fbbf79"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "103e09cf",
      "metadata": {
        "id": "103e09cf"
      },
      "source": [
        "\n",
        "\n",
        "> **QUESTION**: Write a function that takes a `BeautifulSoup` object representing a topic page and returns a list of dictionaries containing information about the top repositories for the topic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "def6b0c3",
      "metadata": {
        "id": "def6b0c3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7582a9a0",
      "metadata": {
        "id": "7582a9a0"
      },
      "source": [
        "We can now use the functions we've defined to get the top repositories for any topic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3f28278",
      "metadata": {
        "id": "f3f28278"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7e66ac22",
      "metadata": {
        "id": "7e66ac22"
      },
      "source": [
        "Here are the top repositories for the keyword `data-analysis`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bb3496c",
      "metadata": {
        "id": "3bb3496c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c2ced693",
      "metadata": {
        "id": "c2ced693"
      },
      "source": [
        "Here are the top repositories for the keyword `python`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59d27141",
      "metadata": {
        "id": "59d27141"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "71ea3c78",
      "metadata": {
        "id": "71ea3c78"
      },
      "source": [
        "Do you see the power of defining functions and using libraries? With just one line of code, we can scrape GitHub and find the top repositories for any topic."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77b1b9b1",
      "metadata": {
        "id": "77b1b9b1"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cc0bf32",
      "metadata": {
        "id": "6cc0bf32"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1d9b6a99",
      "metadata": {
        "id": "1d9b6a99"
      },
      "source": [
        "## Writing information to CSV files\n",
        "\n",
        "Let's create a helper function which takes a list of dictionaries and writes them to a CSV file.\n",
        "\n",
        "The input to our function will be a list of dictionary of the form:\n",
        "\n",
        "```\n",
        "[\n",
        "  {'key1': 'abc', 'key2': 'def', 'key3': 'ghi'},\n",
        "  {'key1': 'jkl', 'key2': 'mno', 'key3': 'pqr'},\n",
        "  {'key1': 'stu', 'key2': 'vwx', 'key3': 'yza'}\n",
        "  ...\n",
        "]\n",
        "```\n",
        "\n",
        "The function will create a file with a given name containing the following data:\n",
        "\n",
        "```\n",
        "key1,key2,key3\n",
        "abc,def,ghi\n",
        "jkl,mno,pqr\n",
        "stu,vwx,yza\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02246120",
      "metadata": {
        "id": "02246120"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "42605109",
      "metadata": {
        "id": "42605109"
      },
      "source": [
        "Let's write the data stored in `top_repos_ml` into a CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48f8f806",
      "metadata": {
        "id": "48f8f806"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dbb192e",
      "metadata": {
        "id": "4dbb192e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "222f9494",
      "metadata": {
        "id": "222f9494"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "0e124a61",
      "metadata": {
        "id": "0e124a61"
      },
      "source": [
        "We can now read the file and inspect its contents. The contents of the file can also be inspected using the \"File > Open\" menu option within Jupyter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebf303f2",
      "metadata": {
        "id": "ebf303f2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5a97bb99",
      "metadata": {
        "id": "5a97bb99"
      },
      "source": [
        "Perfect! We've created a CSV containing the information about the top GitHub repositories for the topic `machine-learning`. We can now put together everything we've done so far to solve the original problem.\n",
        "\n",
        "> **QUESTION**: Write a Python function that creates a CSV file (comma-separated values) containing details about the 25 top GitHub repositories for any given topic. The top repositories for the topic `machine-learning` can be found on this page: [https://github.com/topics/machine-learning](https://github.com/topics/machine-learning). The output CSV should contain these details: repository name, owner's username, no. of stars, repository URL.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7beb924a",
      "metadata": {
        "id": "7beb924a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "83664573",
      "metadata": {
        "id": "83664573"
      },
      "source": [
        "The entire code of this problem is only about 50 lines long. Isn't that neat?\n",
        "\n",
        "Put another way, if you understand these 50 lines of code, you know pretty much all there is to know about web scraping. Use the interactive nature of Jupyter to experiment with each function and add print statements wherever required to display intermediate output. Reading and understanding code is an essential skill for programmers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9207539b",
      "metadata": {
        "id": "9207539b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a79b50d0",
      "metadata": {
        "id": "a79b50d0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59161d29",
      "metadata": {
        "id": "59161d29"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f329a2bf",
      "metadata": {
        "id": "f329a2bf"
      },
      "source": [
        "Now that we have a CSV file, we can use the `pandas` library to view its contents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d27375",
      "metadata": {
        "id": "92d27375"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88c834d6",
      "metadata": {
        "id": "88c834d6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20b8c243",
      "metadata": {
        "id": "20b8c243"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f73a4508",
      "metadata": {
        "scrolled": false,
        "id": "f73a4508"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da0a55c3",
      "metadata": {
        "id": "da0a55c3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2124696",
      "metadata": {
        "id": "f2124696"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a2d95d75",
      "metadata": {
        "id": "a2d95d75"
      },
      "source": [
        "Of course, we can go even further and write a function that scrapes top repositories for several topics.\n",
        "\n",
        "> **EXERCISE**: Write a function `scrape_topics` which takes a list of topics and creates CSV files containing top repositories for a list of topics. Test it out using the empty cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5259df17",
      "metadata": {
        "id": "5259df17"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1b27e6e",
      "metadata": {
        "id": "e1b27e6e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da41c1f0",
      "metadata": {
        "id": "da41c1f0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "347c7497",
      "metadata": {
        "id": "347c7497"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "937fec02",
      "metadata": {
        "id": "937fec02"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b79f6da7",
      "metadata": {
        "id": "b79f6da7"
      },
      "source": [
        "## Using a REST API to retrieve data as JSON\n",
        "\n",
        "Not all URLs point to an HTML page. Consider this URL for example: https://api.github.com/repos/octocat/hello-world . It points to a JSON document, which has a structure like this:\n",
        "\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"Hello-World\",\n",
        "  \"full_name\": \"octocat/Hello-World\",\n",
        "  \"private\": false,\n",
        "  \"owner\": {\n",
        "    \"login\": \"octocat\",\n",
        "    \"id\": 583231,\n",
        "  },\n",
        "  \"html_url\": \"https://github.com/octocat/Hello-World\",\n",
        "}\n",
        "```\n",
        "\n",
        "It's quite similar to a Python dictionary. In fact, you can use the `json` module from python to convert a JSON document into a Python dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d643cbb8",
      "metadata": {
        "id": "d643cbb8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf66e5ab",
      "metadata": {
        "id": "cf66e5ab"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1946e1d5",
      "metadata": {
        "scrolled": true,
        "id": "1946e1d5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1df6324c",
      "metadata": {
        "id": "1df6324c"
      },
      "source": [
        "Unlike HTML, it's really easy to work with JSON using Python, simply fetch the contents of the URL and convert it to a dictionary. Such URLs are often called **REST APIs** or REST API endpoints. Many websites offer well-documented REST APIs to access data from the site in JSON format:\n",
        "\n",
        "* GitHub: https://docs.github.com/en/rest/reference/repos\n",
        "* Facebook: https://developers.facebook.com/docs/groups-api/reference\n",
        "* Twitter: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/timelines/api-reference/get-statuses-user_timeline\n",
        "* Reddit: https://www.reddit.com/dev/api/\n",
        "\n",
        "Using an API is the *officially supported* way of extracting information from a website. To use an API, you will often need to register as a developer on the platform and generate an API key, which you'll need to send with every request to authenticate yourself.\n",
        "\n",
        "Since GitHub offers a public API, we can use it without any restrictions to fetch information about public repositories.\n",
        "\n",
        "\n",
        "> **QUESTION**: Write a function `get_repo_details` to find the following information about a repository: description, watcher count, fork count, open issues count, created at time and updated at time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db28f78b",
      "metadata": {
        "id": "db28f78b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d49b0d4",
      "metadata": {
        "id": "7d49b0d4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "975a9b32",
      "metadata": {
        "id": "975a9b32"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1055cde9",
      "metadata": {
        "id": "1055cde9"
      },
      "source": [
        "> **QUESTION**: Augment the list of top repositories for a topic with the repository description, watcher count, fork count, open issues count, created at time and updated at time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b78b976",
      "metadata": {
        "id": "4b78b976"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b1a618e",
      "metadata": {
        "scrolled": false,
        "id": "2b1a618e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c6f21c37",
      "metadata": {
        "id": "c6f21c37"
      },
      "source": [
        "You may get rate limited if you attempt to make more than 60 requests per hour. To overcome the rate limit, use the Github OAuth token as described here: https://towardsdatascience.com/all-the-things-you-can-do-with-github-api-and-python-f01790fca131\n",
        "\n",
        "Note: Never publish your Github API token publicly, as it can be used to access your Github account. To store your API token without displaying it on the screen, use `getpass`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d555123",
      "metadata": {
        "id": "3d555123"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3d7df188",
      "metadata": {
        "id": "3d7df188"
      },
      "source": [
        "> **EXERCISE**: Augment the list of top repositories for a topic with some additional information about the user/organization the repository belong to: name, description, Github URL, no. of repositories, type (user or organization) etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bec97b1c",
      "metadata": {
        "id": "bec97b1c"
      },
      "source": [
        "### Acronyms\n",
        "\n",
        "In case you're feeling overwhelmed by all the acronyms, here are their expansions:\n",
        "- **REST**: Represetational State Transfer\n",
        "- **API**: Application Programming Interface\n",
        "- **JSON**: JavaScript Object Notation\n",
        "- **URL**: Universal Resource Locator\n",
        "\n",
        "Don't worry, you needn't remember any of them!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "805dad34",
      "metadata": {
        "id": "805dad34"
      },
      "source": [
        "Let's save our work before continuing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52457b64",
      "metadata": {
        "id": "52457b64"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a27d2799",
      "metadata": {
        "id": "a27d2799"
      },
      "source": [
        "## Crawling Websites by Parsing Links on a Page"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4a077a6",
      "metadata": {
        "id": "e4a077a6"
      },
      "source": [
        "When you scrape you a web page, you are likely to find several links on the page. For, example, on the page https://github.com/topics, you will find links to several topic pages. You can parse all the topic page links from this page, and scrape those pages to get the top repositories for each topic. Further, you can parse all the repository links from a topic page and scrape individual repository pages, and so on.\n",
        "\n",
        "The process of scraping a page, parsing links and then using the links to parsing other pages on the same site is called **web crawling**. It's how search engines like Google are able to index and search data from millions of websites on the internet. Python offer libraries like [Scrapy](https://scrapy.org) for crawling websites easily.\n",
        "\n",
        "You can do some basic crawling with `requests`, Beautiful soup, and few simple `for` loops in Python. Here's an exercise to get you started\n",
        "\n",
        "\n",
        "> **EXERCISE**: Get the top 100 repositories for the all the featured topics on GitHub. You might find these URLs useful:\n",
        ">\n",
        "> * Eighth page of featured topics: https://github.com/topics/?page=8  \n",
        "> * Second page of top repositories for a topic: https://github.com/topics/machine-learning?page=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a37b5074",
      "metadata": {
        "id": "a37b5074"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6f0c84c",
      "metadata": {
        "id": "f6f0c84c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "991d81ea",
      "metadata": {
        "id": "991d81ea"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40c2b6a4",
      "metadata": {
        "id": "40c2b6a4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e00d20f",
      "metadata": {
        "id": "3e00d20f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e89aeb13",
      "metadata": {
        "id": "e89aeb13"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2861a53a",
      "metadata": {
        "id": "2861a53a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aec34103",
      "metadata": {
        "id": "aec34103"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb7bc70",
      "metadata": {
        "scrolled": true,
        "id": "0bb7bc70"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "29d74154",
      "metadata": {
        "id": "29d74154"
      },
      "source": [
        "## Summary and Further Reading\n",
        "\n",
        "We've covered the following topics in this tutorial:\n",
        "\n",
        "* Downloading web pages using the requests library\n",
        "* Inspecting the HTML source code of a web page\n",
        "* Parsing parts of a website using Beautiful Soup\n",
        "* Writing parsed information into CSV files\n",
        "* Using a REST API to retrieve data as JSON\n",
        "* Combining data from multiple sources\n",
        "* Using links on a page to crawl a website\n",
        "\n",
        "\n",
        "Here are some things to keep in mind w.r.t. web scraping:\n",
        "\n",
        "* Most websites disallow web scraping for commercial purposes\n",
        "* Prefer using web scraping only for learning and research purposes\n",
        "* Some websites may block your IP or stop sending valid information if you send too many requests\n",
        "* Review the terms and conditions of a website before scraping data from it\n",
        "* Remove sensitive and personally identifiable information before publishing a dataset online\n",
        "* Use official REST APIs wherever available, with proper API keys\n",
        "* Scraping data that you see after logging in is harder (it requires special cookies and headers)\n",
        "* Websites change their HTML layout frequently, which may cause your scarping scripts to break\n",
        "* Websites with dynamic content cannot be scraped using BeautifulSoup. One way to scrape dynamic website is by using Selenium\n",
        "\n",
        "\n",
        "Here are some more examples of scraping:\n",
        "\n",
        "* https://medium.com/@msalmon00/web-scraping-job-postings-from-indeed-96bd588dcb4b\n",
        "* https://medium.com/the-innovation/scraping-medium-with-python-beautiful-soup-3314f898bbf5\n",
        "* https://medium.com/brainstation23/how-to-become-a-pro-with-scraping-youtube-videos-in-3-minutes-a6ac56021961\n",
        "* https://www.freecodecamp.org/news/web-scraping-python-tutorial-how-to-scrape-data-from-a-website/\n",
        "* https://www.freecodecamp.org/news/scraping-wikipedia-articles-with-python/\n",
        "* https://towardsdatascience.com/web-scraping-yahoo-finance-477fe3daa852\n",
        "* https://www.analyticsvidhya.com/blog/2020/10/web-scraping-selenium-in-python/\n",
        "* https://medium.com/ml-book/web-scraping-using-selenium-python-3be7b8762747\n",
        "\n",
        "### Project Ideas\n",
        "\n",
        "Here are some project ideas if you're looking to work on a web scraping project. You can work of one of these ideas, or pick something entirely different.\n",
        "\n",
        "1. **Dataset of Books (Amazon)**: Create a dataset of popular books in different genres by scraping the site: https://www.amazon.in/gp/bestsellers/books/\n",
        "\n",
        "\n",
        "2. **Dataset of Quotes (BrainyQuote)**: Create a dataset of quotes for different tags/topics by scraping the site :https://www.brainyquote.com/topics\n",
        "\n",
        "\n",
        "3. **Dataset of Movies (TMDb)**: The Movie Database (TMDb) contains information about thousands of movies from around the world: https://www.themoviedb.org/movie . Can you scape the site to create a dataset of movies containing information like title, release date, cast, etc. ? You can also create datasets of movie actors/actresses/directors using this site.\n",
        "\n",
        "\n",
        "4. **Dataset of TV Shows (TMDb)**: The Movie Database (TMDb) contains information about thousands of TV shows from around the world: https://www.themoviedb.org/tv . Can you scrape the site to create a dataset of TV shows containing information like title, release date, cast, crew, etc. ? You can also create datasets of TV actors/actresses/directors using this site.\n",
        "\n",
        "\n",
        "5. **Collections of Popular Repositories (GitHub)**: Scape GitHub collections ( https://github.com/collections ) to create a dataset of popular repositories organized by different use cases.\n",
        "\n",
        "\n",
        "6. **Dataset of Books (BooksToScrape)**: Create a dataset of popular books in different genres by scraping the site *Books To Scrape*: http://books.toscrape.com\n",
        "\n",
        "\n",
        "7. **Dataset of Quotes (QuotesToScrape)**: Create a dataset of popular quotes for different tags by scraping the site *Quotes To Scrape*: http://quotes.toscrape.com\n",
        "\n",
        "\n",
        "8. **Scrape a User's Repositories (GitHub)**: Given someone's GitHub username, can you scrape their GitHub profile to create a list of their repositories with information like repository name, no. of stars, no. of forks, etc.?\n",
        "\n",
        "\n",
        "9. **Scrape User's Reviews (ConsumerAffairs)**: Consumeraffairs contains reviews about thousands of brands: https://www.consumeraffairs.com/. Can you scrape any category from the site to create a dataset of Reviews containing information like Title, Rating, Reviews and toll-free number etc.?.\n",
        "\n",
        "\n",
        "10. **Songs Dataset (AZLyrics)**: Create a dataset of songs by scraping AZLyrics: https://www.azlyrics.com/f.html . Capture information like song title, artist name, year of release and lyrics URL.\n",
        "\n",
        "\n",
        "11. **Scrape a Popular Blog**: Create a dataset of blog posts on a popular blog e.g. https://m.signalvnoise.com/search/ . The dataset can contain information like the blog title, published date, tags, author, link to blog post, etc.\n",
        "\n",
        "\n",
        "12. **Weekly Top Songs (Top 40 Weekly)**: Create a dataset of the top 40 songs of each week in a given year by scraping the site https://top40weekly.com . Capture information like song title, artist, weekly rank, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96af5186",
      "metadata": {
        "id": "96af5186"
      },
      "source": [
        "## Questions for Revision\n",
        "1. Why do we need to scrape websites?\n",
        "2. What different tools can we use to scrape websites?\n",
        "3. What are the applications of web-scraping?\n",
        "4. What are the steps involved in web-scraping?\n",
        "5. What are the techniques to get data from websites?\n",
        "6. What technique is used to retrieve data in a machine-readable format in python?\n",
        "7. How can one download a webpage from the internet using python?\n",
        "8. What library do we need for downloading the webpage in python?\n",
        "9. What function from the library do we need for downloading the webpage?\n",
        "10. How do we make sure that the webpage is downloaded successfully?\n",
        "11. How can we access the content of the downloaded webpage?\n",
        "12. What function do we need to find out the total number of characters in the downloaded webpage?\n",
        "13. What defines the content and structure of the downloaded webpage?\n",
        "14. What is a source code? In what language is it usually written in?\n",
        "15. How different are the original webpage and scraped webpage?\n",
        "16. How many parts does HTML tag have? What are they?\n",
        "17. Is it possible to be blocked by website when you scrape more pages? If yes, how can one avoid this?\n",
        "18. How do we get the information we need from the downloaded website?\n",
        "19. What library do we need to install to extract information from HTML source code?\n",
        "20. What is doc object?\n",
        "21. How can we access attributes of a tag?\n",
        "22. How do we find the direct children of the tag?\n",
        "23. What is the purpose of strip()?\n",
        "24. How can we write the extracted information into CSV files?\n",
        "25. What are REST APIs? How are they different from usual URLs?\n",
        "26. What is the official way to extract information from a website? What do we need for that? How does it help one in extracting information?\n",
        "27. What websites offer public APIs?\n",
        "28. Can we extract data from all the websites on web? If not, why?\n",
        "29. What is getpass()?\n",
        "30. What is web crawling and how is it different from web scraping?\n",
        "31. What are the applications of web crawling?\n",
        "32. What does python offer for crawling websites?\n",
        "33. How do we extract data from dynamic websites?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c761bcd",
      "metadata": {
        "id": "7c761bcd"
      },
      "source": [
        "## Solutions for Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8250d3b",
      "metadata": {
        "id": "f8250d3b"
      },
      "source": [
        "> **EXERCISE**: Find the first occurrence of each of these tags in `doc`: `div`, `img`, `span`, `p`, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0b1898d",
      "metadata": {
        "id": "f0b1898d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eed3415e",
      "metadata": {
        "id": "eed3415e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58716acc",
      "metadata": {
        "id": "58716acc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "914b0762",
      "metadata": {
        "id": "914b0762"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c9ee0c4e",
      "metadata": {
        "id": "c9ee0c4e"
      },
      "source": [
        "> **EXERCISE**: Get a list of all the `img` tags on the page. How many images does the page contain?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79887129",
      "metadata": {
        "id": "79887129"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bad547ac",
      "metadata": {
        "id": "bad547ac"
      },
      "source": [
        "> **EXERCISE**: Find the 5th image tag on the page (counting from 0). Which attributes does the tag contain? Find the values of the `src` and `alt` attributes of the tag."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2260207d",
      "metadata": {
        "id": "2260207d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46173a9b",
      "metadata": {
        "id": "46173a9b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "742b6213",
      "metadata": {
        "id": "742b6213"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3e1c4b8a",
      "metadata": {
        "id": "3e1c4b8a"
      },
      "source": [
        "> **EXERCISE**: Find the `src` attribute of the first `img` tag with the `alt` attribute set to `julia`. Visit the link and check what the image represents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acbfb4be",
      "metadata": {
        "id": "acbfb4be"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "aa228941",
      "metadata": {
        "id": "aa228941"
      },
      "source": [
        "> **EXERCISE**: Find the list of all the images matching the class `d-block width-full`. Each list element should be a dictionary containing two keys, `\"username\"` and `\"url\"`. You can obtain the username using the `alt` attribute of a tag and the URL using the `src` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a01755",
      "metadata": {
        "id": "77a01755"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fb663cc8",
      "metadata": {
        "id": "fb663cc8"
      },
      "source": [
        "> **EXERCISE**: Write a function `scrape_topics` which takes a list of topics and creates CSV files containing top repositories for a list of topics. Test it out using the empty cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c47c0de7",
      "metadata": {
        "id": "c47c0de7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81fe57af",
      "metadata": {
        "id": "81fe57af"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b8bd7b9",
      "metadata": {
        "id": "3b8bd7b9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a70109",
      "metadata": {
        "id": "16a70109"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baf6d0a2",
      "metadata": {
        "id": "baf6d0a2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "575fc1f5",
      "metadata": {
        "id": "575fc1f5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dcaa5dc1",
      "metadata": {
        "id": "dcaa5dc1"
      },
      "source": [
        "> **EXERCISE**: Get the top 100 repositories for the all the featured topics on GitHub. You might find these URLs useful:\n",
        ">\n",
        "> * Eighth page of featured topics: https://github.com/topics/?page=8  \n",
        "> * Second page of top repositories for a topic: https://github.com/topics/machine-learning?page=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fd6573c",
      "metadata": {
        "id": "0fd6573c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d64cbd0",
      "metadata": {
        "id": "1d64cbd0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8be16813",
      "metadata": {
        "id": "8be16813"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d691725",
      "metadata": {
        "id": "4d691725"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33dc4dfa",
      "metadata": {
        "id": "33dc4dfa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "870a4a1d",
      "metadata": {
        "id": "870a4a1d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5dee78d7",
      "metadata": {
        "id": "5dee78d7"
      },
      "source": [
        "Try to combine each topic's all pages CSVs into single one ;)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}